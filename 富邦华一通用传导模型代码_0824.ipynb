{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H0evFBd2Rjty"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import itertools\n",
        "import copy\n",
        "import time\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.tsa.vector_ar.vecm import coint_johansen #the Johansen cointegration test for determining the cointegration rank of a VECM\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.api import VAR\n",
        "# adfuller为ADF检验，coint为协整检验\n",
        "from statsmodels.tsa.stattools import adfuller, coint #the augmented Engle-Granger two-step cointegration test\n",
        "import statsmodels.stats.diagnostic"
      ],
      "id": "H0evFBd2Rjty"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vmMo-wW-Rjt2"
      },
      "outputs": [],
      "source": [
        "# 通过警告过滤器进行控制是否发出警告消息\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "vmMo-wW-Rjt2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ-hEgyuRjt3"
      },
      "source": [
        "## 1.导入数据&处理变量"
      ],
      "id": "fZ-hEgyuRjt3"
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "D_UDVPTdRjt6",
        "outputId": "8e849cd2-fc46-4b83-dbc0-29cde08d07c8",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            fubon_npl  gdp_cn_lg  gdp_cn_yoy  export_gr_yoy  energy_cspt_lg  \\\n",
              "年份     季度                                                                     \n",
              "2013.0 4.0   0.008206  -1.182989   -0.278078       0.129075       -1.264861   \n",
              "2014.0 1.0   0.011958  -1.949924   -0.301597      -0.683967       -1.409404   \n",
              "       2.0   0.014252  -1.502567   -0.289838      -0.374579       -1.255767   \n",
              "       3.0   0.009055  -1.317760   -0.338184      -0.072387       -1.103768   \n",
              "       4.0   0.008564  -0.875369   -0.327730      -0.000436       -0.953374   \n",
              "2015.0 1.0   0.011251  -1.650291   -0.352557      -0.101167       -1.102861   \n",
              "       2.0   0.009885  -1.203301   -0.353863      -0.374579       -1.026569   \n",
              "       3.0   0.010819  -1.023952   -0.372156      -0.576041       -0.950682   \n",
              "       4.0   0.009951  -0.583818   -0.378690      -0.647991       -0.875198   \n",
              "\n",
              "              oil_rt  coal_cspt_lg  gas_cspt_lg  coal_cspt_yoy  oil_cspt_yoy  \n",
              "年份     季度                                                                     \n",
              "2013.0 4.0 -2.163568      0.663034    -1.428546       0.820719      0.080719  \n",
              "2014.0 1.0 -2.084413     -0.149182    -1.412332       0.541832     -0.007009  \n",
              "       2.0 -2.005258      0.092671    -1.310147       0.186885     -0.182463  \n",
              "       3.0 -1.926103      0.326901    -1.209225      -0.161724     -0.357918  \n",
              "       4.0 -1.846948      0.553609    -1.109534      -0.510332     -0.517423  \n",
              "2015.0 1.0 -1.411596     -0.360665    -1.116172      -0.637099      0.519356  \n",
              "       2.0 -0.976244     -0.478400    -1.057427      -1.087121      1.117498  \n",
              "       3.0 -0.540892     -0.600579    -0.999119      -1.524467      1.715640  \n",
              "       4.0 -0.105540     -0.727232    -0.941242      -1.961812      2.297831  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e0f8183-6e1d-48ad-9dee-774e4482be95\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>fubon_npl</th>\n",
              "      <th>gdp_cn_lg</th>\n",
              "      <th>gdp_cn_yoy</th>\n",
              "      <th>export_gr_yoy</th>\n",
              "      <th>energy_cspt_lg</th>\n",
              "      <th>oil_rt</th>\n",
              "      <th>coal_cspt_lg</th>\n",
              "      <th>gas_cspt_lg</th>\n",
              "      <th>coal_cspt_yoy</th>\n",
              "      <th>oil_cspt_yoy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>年份</th>\n",
              "      <th>季度</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013.0</th>\n",
              "      <th>4.0</th>\n",
              "      <td>0.008206</td>\n",
              "      <td>-1.182989</td>\n",
              "      <td>-0.278078</td>\n",
              "      <td>0.129075</td>\n",
              "      <td>-1.264861</td>\n",
              "      <td>-2.163568</td>\n",
              "      <td>0.663034</td>\n",
              "      <td>-1.428546</td>\n",
              "      <td>0.820719</td>\n",
              "      <td>0.080719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">2014.0</th>\n",
              "      <th>1.0</th>\n",
              "      <td>0.011958</td>\n",
              "      <td>-1.949924</td>\n",
              "      <td>-0.301597</td>\n",
              "      <td>-0.683967</td>\n",
              "      <td>-1.409404</td>\n",
              "      <td>-2.084413</td>\n",
              "      <td>-0.149182</td>\n",
              "      <td>-1.412332</td>\n",
              "      <td>0.541832</td>\n",
              "      <td>-0.007009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>0.014252</td>\n",
              "      <td>-1.502567</td>\n",
              "      <td>-0.289838</td>\n",
              "      <td>-0.374579</td>\n",
              "      <td>-1.255767</td>\n",
              "      <td>-2.005258</td>\n",
              "      <td>0.092671</td>\n",
              "      <td>-1.310147</td>\n",
              "      <td>0.186885</td>\n",
              "      <td>-0.182463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>0.009055</td>\n",
              "      <td>-1.317760</td>\n",
              "      <td>-0.338184</td>\n",
              "      <td>-0.072387</td>\n",
              "      <td>-1.103768</td>\n",
              "      <td>-1.926103</td>\n",
              "      <td>0.326901</td>\n",
              "      <td>-1.209225</td>\n",
              "      <td>-0.161724</td>\n",
              "      <td>-0.357918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>0.008564</td>\n",
              "      <td>-0.875369</td>\n",
              "      <td>-0.327730</td>\n",
              "      <td>-0.000436</td>\n",
              "      <td>-0.953374</td>\n",
              "      <td>-1.846948</td>\n",
              "      <td>0.553609</td>\n",
              "      <td>-1.109534</td>\n",
              "      <td>-0.510332</td>\n",
              "      <td>-0.517423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"4\" valign=\"top\">2015.0</th>\n",
              "      <th>1.0</th>\n",
              "      <td>0.011251</td>\n",
              "      <td>-1.650291</td>\n",
              "      <td>-0.352557</td>\n",
              "      <td>-0.101167</td>\n",
              "      <td>-1.102861</td>\n",
              "      <td>-1.411596</td>\n",
              "      <td>-0.360665</td>\n",
              "      <td>-1.116172</td>\n",
              "      <td>-0.637099</td>\n",
              "      <td>0.519356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>0.009885</td>\n",
              "      <td>-1.203301</td>\n",
              "      <td>-0.353863</td>\n",
              "      <td>-0.374579</td>\n",
              "      <td>-1.026569</td>\n",
              "      <td>-0.976244</td>\n",
              "      <td>-0.478400</td>\n",
              "      <td>-1.057427</td>\n",
              "      <td>-1.087121</td>\n",
              "      <td>1.117498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>0.010819</td>\n",
              "      <td>-1.023952</td>\n",
              "      <td>-0.372156</td>\n",
              "      <td>-0.576041</td>\n",
              "      <td>-0.950682</td>\n",
              "      <td>-0.540892</td>\n",
              "      <td>-0.600579</td>\n",
              "      <td>-0.999119</td>\n",
              "      <td>-1.524467</td>\n",
              "      <td>1.715640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>0.009951</td>\n",
              "      <td>-0.583818</td>\n",
              "      <td>-0.378690</td>\n",
              "      <td>-0.647991</td>\n",
              "      <td>-0.875198</td>\n",
              "      <td>-0.105540</td>\n",
              "      <td>-0.727232</td>\n",
              "      <td>-0.941242</td>\n",
              "      <td>-1.961812</td>\n",
              "      <td>2.297831</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e0f8183-6e1d-48ad-9dee-774e4482be95')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9e0f8183-6e1d-48ad-9dee-774e4482be95 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9e0f8183-6e1d-48ad-9dee-774e4482be95');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "# 从Excel导入数据\n",
        "# 运行之前请修改下一行的文件路径\n",
        "filepath = r'通用行业模型结果_iris_v0.4-自动化测算-量纲统一(1).xlsx'\n",
        "def read_excel():\n",
        "    data = pd.read_excel(filepath, sheet_name='建模数据',index_col=[0,1],skiprows=1,usecols=range(0,12))\n",
        "    return data\n",
        "\n",
        "data = read_excel()\n",
        "data.head(9)"
      ],
      "id": "D_UDVPTdRjt6"
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "zhnGmMygRjt_"
      },
      "outputs": [],
      "source": [
        "# 修改data的index为时间序列\n",
        "start_q = datetime.datetime.strptime(str(data.index[0][0])+'-03-31','%Y.0-%m-%d').date()\n",
        "data.index = pd.date_range(start_q,periods=len(data),freq='Q-DEC')"
      ],
      "id": "zhnGmMygRjt_"
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "BF-wFHWXRjuA",
        "outputId": "b86b3cd2-78f2-4551-a51b-22c28d2197c2",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            fubon_npl  gdp_cn_lg  gdp_cn_yoy  export_gr_yoy  energy_cspt_lg  \\\n",
              "2013-03-31   0.008206  -1.182989   -0.278078       0.129075       -1.264861   \n",
              "2013-06-30   0.011958  -1.949924   -0.301597      -0.683967       -1.409404   \n",
              "2013-09-30   0.014252  -1.502567   -0.289838      -0.374579       -1.255767   \n",
              "2013-12-31   0.009055  -1.317760   -0.338184      -0.072387       -1.103768   \n",
              "2014-03-31   0.008564  -0.875369   -0.327730      -0.000436       -0.953374   \n",
              "2014-06-30   0.011251  -1.650291   -0.352557      -0.101167       -1.102861   \n",
              "2014-09-30   0.009885  -1.203301   -0.353863      -0.374579       -1.026569   \n",
              "2014-12-31   0.010819  -1.023952   -0.372156      -0.576041       -0.950682   \n",
              "2015-03-31   0.009951  -0.583818   -0.378690      -0.647991       -0.875198   \n",
              "\n",
              "              oil_rt  coal_cspt_lg  gas_cspt_lg  coal_cspt_yoy  oil_cspt_yoy  \n",
              "2013-03-31 -2.163568      0.663034    -1.428546       0.820719      0.080719  \n",
              "2013-06-30 -2.084413     -0.149182    -1.412332       0.541832     -0.007009  \n",
              "2013-09-30 -2.005258      0.092671    -1.310147       0.186885     -0.182463  \n",
              "2013-12-31 -1.926103      0.326901    -1.209225      -0.161724     -0.357918  \n",
              "2014-03-31 -1.846948      0.553609    -1.109534      -0.510332     -0.517423  \n",
              "2014-06-30 -1.411596     -0.360665    -1.116172      -0.637099      0.519356  \n",
              "2014-09-30 -0.976244     -0.478400    -1.057427      -1.087121      1.117498  \n",
              "2014-12-31 -0.540892     -0.600579    -0.999119      -1.524467      1.715640  \n",
              "2015-03-31 -0.105540     -0.727232    -0.941242      -1.961812      2.297831  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb5e6ec7-4c19-423c-a68b-bcd1467d1cb1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fubon_npl</th>\n",
              "      <th>gdp_cn_lg</th>\n",
              "      <th>gdp_cn_yoy</th>\n",
              "      <th>export_gr_yoy</th>\n",
              "      <th>energy_cspt_lg</th>\n",
              "      <th>oil_rt</th>\n",
              "      <th>coal_cspt_lg</th>\n",
              "      <th>gas_cspt_lg</th>\n",
              "      <th>coal_cspt_yoy</th>\n",
              "      <th>oil_cspt_yoy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-03-31</th>\n",
              "      <td>0.008206</td>\n",
              "      <td>-1.182989</td>\n",
              "      <td>-0.278078</td>\n",
              "      <td>0.129075</td>\n",
              "      <td>-1.264861</td>\n",
              "      <td>-2.163568</td>\n",
              "      <td>0.663034</td>\n",
              "      <td>-1.428546</td>\n",
              "      <td>0.820719</td>\n",
              "      <td>0.080719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-06-30</th>\n",
              "      <td>0.011958</td>\n",
              "      <td>-1.949924</td>\n",
              "      <td>-0.301597</td>\n",
              "      <td>-0.683967</td>\n",
              "      <td>-1.409404</td>\n",
              "      <td>-2.084413</td>\n",
              "      <td>-0.149182</td>\n",
              "      <td>-1.412332</td>\n",
              "      <td>0.541832</td>\n",
              "      <td>-0.007009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-09-30</th>\n",
              "      <td>0.014252</td>\n",
              "      <td>-1.502567</td>\n",
              "      <td>-0.289838</td>\n",
              "      <td>-0.374579</td>\n",
              "      <td>-1.255767</td>\n",
              "      <td>-2.005258</td>\n",
              "      <td>0.092671</td>\n",
              "      <td>-1.310147</td>\n",
              "      <td>0.186885</td>\n",
              "      <td>-0.182463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-12-31</th>\n",
              "      <td>0.009055</td>\n",
              "      <td>-1.317760</td>\n",
              "      <td>-0.338184</td>\n",
              "      <td>-0.072387</td>\n",
              "      <td>-1.103768</td>\n",
              "      <td>-1.926103</td>\n",
              "      <td>0.326901</td>\n",
              "      <td>-1.209225</td>\n",
              "      <td>-0.161724</td>\n",
              "      <td>-0.357918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-03-31</th>\n",
              "      <td>0.008564</td>\n",
              "      <td>-0.875369</td>\n",
              "      <td>-0.327730</td>\n",
              "      <td>-0.000436</td>\n",
              "      <td>-0.953374</td>\n",
              "      <td>-1.846948</td>\n",
              "      <td>0.553609</td>\n",
              "      <td>-1.109534</td>\n",
              "      <td>-0.510332</td>\n",
              "      <td>-0.517423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-06-30</th>\n",
              "      <td>0.011251</td>\n",
              "      <td>-1.650291</td>\n",
              "      <td>-0.352557</td>\n",
              "      <td>-0.101167</td>\n",
              "      <td>-1.102861</td>\n",
              "      <td>-1.411596</td>\n",
              "      <td>-0.360665</td>\n",
              "      <td>-1.116172</td>\n",
              "      <td>-0.637099</td>\n",
              "      <td>0.519356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-09-30</th>\n",
              "      <td>0.009885</td>\n",
              "      <td>-1.203301</td>\n",
              "      <td>-0.353863</td>\n",
              "      <td>-0.374579</td>\n",
              "      <td>-1.026569</td>\n",
              "      <td>-0.976244</td>\n",
              "      <td>-0.478400</td>\n",
              "      <td>-1.057427</td>\n",
              "      <td>-1.087121</td>\n",
              "      <td>1.117498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-12-31</th>\n",
              "      <td>0.010819</td>\n",
              "      <td>-1.023952</td>\n",
              "      <td>-0.372156</td>\n",
              "      <td>-0.576041</td>\n",
              "      <td>-0.950682</td>\n",
              "      <td>-0.540892</td>\n",
              "      <td>-0.600579</td>\n",
              "      <td>-0.999119</td>\n",
              "      <td>-1.524467</td>\n",
              "      <td>1.715640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-03-31</th>\n",
              "      <td>0.009951</td>\n",
              "      <td>-0.583818</td>\n",
              "      <td>-0.378690</td>\n",
              "      <td>-0.647991</td>\n",
              "      <td>-0.875198</td>\n",
              "      <td>-0.105540</td>\n",
              "      <td>-0.727232</td>\n",
              "      <td>-0.941242</td>\n",
              "      <td>-1.961812</td>\n",
              "      <td>2.297831</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb5e6ec7-4c19-423c-a68b-bcd1467d1cb1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb5e6ec7-4c19-423c-a68b-bcd1467d1cb1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb5e6ec7-4c19-423c-a68b-bcd1467d1cb1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "data.head(9)"
      ],
      "id": "BF-wFHWXRjuA"
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "dDZDGfv1RjuB"
      },
      "outputs": [],
      "source": [
        "# 定义自变量和因变量\n",
        "X = data.iloc[:,1:data.columns.size]\n",
        "# Z score standardization\n",
        "X = (X-X.mean(axis=0))/X.std(axis=0)\n",
        "Y = np.log(data['fubon_npl']/(1-data['fubon_npl']))"
      ],
      "id": "dDZDGfv1RjuB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjCzRgqnRjuC"
      },
      "source": [
        "## 2.ADF 检验"
      ],
      "id": "KjCzRgqnRjuC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_WlMoFIRjuD"
      },
      "source": [
        "### 2.1 自变量ADF检验"
      ],
      "id": "Z_WlMoFIRjuD"
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow5dHOk_RjuF",
        "outputId": "e1a1473b-2b97-4282-c5e3-18710cbe0c33",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-1.039333806906561, 0.73864933189139, 8, 25, {'1%': -3.7238633119999998, '5%': -2.98648896, '10%': -2.6328004}, 11.187835183525614)\n"
          ]
        }
      ],
      "source": [
        "result1 = adfuller(data['gdp_cn_lg'].values)\n",
        "print(result1)"
      ],
      "id": "ow5dHOk_RjuF"
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YTHS4oYRjuH",
        "outputId": "84a57652-a6c3-416e-c7a1-681605004bf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADF Statistic: -1.039334\n",
            "p-value: 0.738649\n",
            "Criticla Values：\n",
            "\t1%: -3.724\n",
            "\t5%: -2.986\n",
            "\t10%: -2.633\n",
            "Rejected Null Hypothesis - so the time series is non stationary\n"
          ]
        }
      ],
      "source": [
        "print('ADF Statistic: %f' % result1[0])\n",
        "print('p-value: %f' % result1[1])\n",
        "print('Criticla Values：')\n",
        "for key, value in result1[4].items():\n",
        "    print('\\t%s: %.3f' % (key,value))\n",
        "if result1[0] < result1[4][\"5%\"]:\n",
        "    print('Fail to reject Null Hypothesis - so the time series is stationary')\n",
        "else:\n",
        "    print('Rejected Null Hypothesis - so the time series is non stationary')"
      ],
      "id": "0YTHS4oYRjuH"
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUQwL8W0RjuI",
        "outputId": "bae683a2-d1f8-45c4-db54-38b79d399396",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-1.6420231886376953, 0.46120381446905645, 4, 29, {'1%': -3.6790595944893187, '5%': -2.9678817237279103, '10%': -2.6231583472057074}, 61.40486343959045)\n"
          ]
        }
      ],
      "source": [
        "result2 = adfuller(data['gdp_cn_yoy'].values)\n",
        "print(result2)"
      ],
      "id": "nUQwL8W0RjuI"
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNThkPzqRjuK",
        "outputId": "cc0f2dd5-5fed-46a5-fb50-ad2bb1a72149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-0.8725996024409416, 0.7968618097266423, 8, 25, {'1%': -3.7238633119999998, '5%': -2.98648896, '10%': -2.6328004}, 53.105966128236936)\n"
          ]
        }
      ],
      "source": [
        "result3 = adfuller(data['export_gr_yoy'].values)\n",
        "print(result3)"
      ],
      "id": "BNThkPzqRjuK"
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCgoL4bURjuM",
        "outputId": "c89b4543-d224-4191-d6d3-37a970050dd9",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1.7183907821551814, 0.9981726475288757, 5, 28, {'1%': -3.6889256286443146, '5%': -2.9719894897959187, '10%': -2.6252957653061224}, -44.63579678961426)\n"
          ]
        }
      ],
      "source": [
        "result4 = adfuller(data['energy_cspt_lg'].values)\n",
        "print(result4)"
      ],
      "id": "aCgoL4bURjuM"
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlmynsHCRjuN",
        "outputId": "b7aa222b-4184-4936-fcfe-19a90e95e586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-2.7169434857834696, 0.07115191703073966, 1, 32, {'1%': -3.653519805908203, '5%': -2.9572185644531253, '10%': -2.6175881640625}, -85.47931256954035)\n"
          ]
        }
      ],
      "source": [
        "result5 = adfuller(data['oil_rt'].values)\n",
        "print(result5)"
      ],
      "id": "HlmynsHCRjuN"
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVDjY8-8RjuQ",
        "outputId": "d0f1456b-484d-4dfb-8302-908b3d39c14a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1.0303572076532932, 0.994576146409935, 5, 28, {'1%': -3.6889256286443146, '5%': -2.9719894897959187, '10%': -2.6252957653061224}, 10.747413639688439)\n"
          ]
        }
      ],
      "source": [
        "result6 = adfuller(data['coal_cspt_lg'].values)\n",
        "print(result6)"
      ],
      "id": "sVDjY8-8RjuQ"
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ET1w8MC5qINc",
        "outputId": "25605623-63cc-46ac-e351-690e35eabf7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.6851722872158181, 0.9895372641734121, 8, 25, {'1%': -3.7238633119999998, '5%': -2.98648896, '10%': -2.6328004}, -79.93748939374026)\n"
          ]
        }
      ],
      "source": [
        "result7 = adfuller(data['gas_cspt_lg'].values)\n",
        "print(result7)"
      ],
      "id": "ET1w8MC5qINc"
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UiYtoPeqINd",
        "outputId": "7deb41f3-3c1c-475d-8fe2-02bbbc20754e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-0.030894493844477094, 0.9559013304672457, 1, 32, {'1%': -3.653519805908203, '5%': -2.9572185644531253, '10%': -2.6175881640625}, 18.884347768791145)\n"
          ]
        }
      ],
      "source": [
        "result8 = adfuller(data['coal_cspt_yoy'].values)\n",
        "print(result8)"
      ],
      "id": "5UiYtoPeqINd"
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGnePRN_RjuR",
        "outputId": "a7fd8cb1-04ba-466b-9fca-a3993d05422a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-2.719389458610353, 0.07074272294260672, 1, 32, {'1%': -3.653519805908203, '5%': -2.9572185644531253, '10%': -2.6175881640625}, 28.8776020596437)\n"
          ]
        }
      ],
      "source": [
        "result9 = adfuller(data['oil_cspt_yoy'].values)\n",
        "print(result9)"
      ],
      "id": "CGnePRN_RjuR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sei3pQnnRjuV"
      },
      "source": [
        "### 2.2 y值平稳性检验"
      ],
      "id": "sei3pQnnRjuV"
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VGIil-ERjuW",
        "outputId": "baf08f87-2d8c-4884-f56d-7efbb437256a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-2.0444691061142386, 0.2674215329996303, 9, 24, {'1%': -3.7377092158564813, '5%': -2.9922162731481485, '10%': -2.635746736111111}, -225.85939450947404)\n"
          ]
        }
      ],
      "source": [
        "result10 = adfuller(data['fubon_npl'].values)\n",
        "print(result10)"
      ],
      "id": "8VGIil-ERjuW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNeLgR4nRjuY"
      },
      "source": [
        "## 3. 一阶差分"
      ],
      "id": "TNeLgR4nRjuY"
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ShGWpEHRjuY",
        "outputId": "d469789e-a785-4eb5-b289-4b15b5ee23b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-1.4345007968426375, 0.5656288575610321, 7, 25, {'1%': -3.7238633119999998, '5%': -2.98648896, '10%': -2.6328004}, 9.92801989287102)\n"
          ]
        }
      ],
      "source": [
        "X_diff1 = np.diff(data['gdp_cn_lg'].values)\n",
        "r_result1 = adfuller (X_diff1)\n",
        "print(r_result1)"
      ],
      "id": "0ShGWpEHRjuY"
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwWsBxAaRjuZ",
        "outputId": "d9f9422c-bbd9-4447-d407-20175da6e018"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-4.740430949534757, 7.060473497306051e-05, 3, 29, {'1%': -3.6790595944893187, '5%': -2.9678817237279103, '10%': -2.6231583472057074}, 61.164126391346635)\n"
          ]
        }
      ],
      "source": [
        "X_diff2 = np.diff(data['gdp_cn_yoy'].values)\n",
        "r_result2 = adfuller (X_diff2)\n",
        "print(r_result2)"
      ],
      "id": "FwWsBxAaRjuZ"
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyIytMKaRjuZ",
        "outputId": "3239f5e8-71fa-4c54-cb5c-c18db44a6bc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-3.09725350268536, 0.026757110368554233, 7, 25, {'1%': -3.7238633119999998, '5%': -2.98648896, '10%': -2.6328004}, 51.74626237767511)\n"
          ]
        }
      ],
      "source": [
        "X_diff3 = np.diff(data['export_gr_yoy'].values)\n",
        "r_result3 = adfuller (X_diff3)\n",
        "print(r_result3)"
      ],
      "id": "hyIytMKaRjuZ"
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3vLogdkRjua",
        "outputId": "415cd329-b0bf-4614-ea18-f86a66c17e5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-0.41823460779578253, 0.9070094445187573, 4, 28, {'1%': -3.6889256286443146, '5%': -2.9719894897959187, '10%': -2.6252957653061224}, -40.76137121057424)\n"
          ]
        }
      ],
      "source": [
        "X_diff4 = np.diff(data['energy_cspt_lg'].values)\n",
        "r_result4 = adfuller (X_diff4)\n",
        "print(r_result4)"
      ],
      "id": "U3vLogdkRjua"
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TXUIa9eRjua",
        "outputId": "b6ec905f-c45f-4fc8-b9ce-593ed2faeeb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-1.2575861543906481, 0.6483465748214632, 0, 32, {'1%': -3.653519805908203, '5%': -2.9572185644531253, '10%': -2.6175881640625}, -82.18564636173275)\n"
          ]
        }
      ],
      "source": [
        "X_diff5 = np.diff(data['oil_rt'].values)\n",
        "r_result5 = adfuller (X_diff5)\n",
        "print(r_result5)"
      ],
      "id": "-TXUIa9eRjua"
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_peuKasHRjub",
        "outputId": "2df7d898-6435-4da5-c36f-1d593295fc26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.08406513219879291, 0.9649561552904635, 4, 28, {'1%': -3.6889256286443146, '5%': -2.9719894897959187, '10%': -2.6252957653061224}, 13.303455135119215)\n"
          ]
        }
      ],
      "source": [
        "X_diff6 = np.diff(data['coal_cspt_lg'].values)\n",
        "r_result6 = adfuller (X_diff6)\n",
        "print(r_result6)"
      ],
      "id": "_peuKasHRjub"
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osIJJI4lqINg",
        "outputId": "a0e16f35-0e10-4560-f7db-27f7e7c9ef00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-3.658869191685659, 0.004730333302934265, 7, 25, {'1%': -3.7238633119999998, '5%': -2.98648896, '10%': -2.6328004}, -78.0008255238478)\n"
          ]
        }
      ],
      "source": [
        "X_diff7 = np.diff(data['gas_cspt_lg'].values)\n",
        "r_result7 = adfuller (X_diff7)\n",
        "print(r_result7)"
      ],
      "id": "osIJJI4lqINg"
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "HuQlcTERqINh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f4f42a-a1d4-4f8c-d4f0-023e707689d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-2.673091044825907, 0.07881155953800628, 0, 32, {'1%': -3.653519805908203, '5%': -2.9572185644531253, '10%': -2.6175881640625}, 17.422146397979958)\n"
          ]
        }
      ],
      "source": [
        "X_diff8 = np.diff(data['coal_cspt_yoy'].values)\n",
        "r_result8 = adfuller (X_diff8)\n",
        "print(r_result8)"
      ],
      "id": "HuQlcTERqINh"
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "CWFYjbSBRjuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e96bb28d-78bb-4a4e-e0c1-ef8576bb564a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-3.0672459167813315, 0.02907402275692347, 0, 32, {'1%': -3.653519805908203, '5%': -2.9572185644531253, '10%': -2.6175881640625}, 30.970900594896534)\n"
          ]
        }
      ],
      "source": [
        "X_diff9 = np.diff(data['oil_cspt_yoy'].values)\n",
        "r_result9 = adfuller (X_diff9)\n",
        "print(r_result9)"
      ],
      "id": "CWFYjbSBRjuc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-fzno0ZRjud"
      },
      "source": [
        "根据一阶差分后的ADF统计值，发现所有指标的一阶差分至少可在5%的置信水平拒绝单位根假设。"
      ],
      "id": "P-fzno0ZRjud"
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "Ln4y6PfHRjue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "074eb53c-1113-44f9-f8c3-a5da78200713"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(-1.3501292781737304, 0.6059377685158636, 9, 23, {'1%': -3.7529275211638033, '5%': -2.998499866852963, '10%': -2.6389669754253307}, -221.58437077097403)\n"
          ]
        }
      ],
      "source": [
        "# y值一阶差分平稳\n",
        "Y_diff = np.diff(data['fubon_npl'].values)\n",
        "r_result_y = adfuller (Y_diff)\n",
        "print(r_result_y)"
      ],
      "id": "Ln4y6PfHRjue"
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "NVT9vC1ORjue"
      },
      "outputs": [],
      "source": [
        "X_dif1 = [X_diff1]+ [X_diff2]+ [X_diff3]+ [X_diff4]+ [X_diff5]+ [X_diff6]+ [X_diff7]+ [X_diff8]+ [X_diff9]"
      ],
      "id": "NVT9vC1ORjue"
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "eepPMkukRjue",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a03627af-f026-46f9-a5ad-7a01dd8ee5e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    gdp_cn_lg  gdp_cn_yoy  export_gr_yoy  energy_cspt_lg    oil_rt  \\\n",
              "0   -0.766935   -0.023520      -0.813042       -0.144543  0.079155   \n",
              "1    0.447357    0.011760       0.309388        0.153637  0.079155   \n",
              "2    0.184807   -0.048346       0.302193        0.151998  0.079155   \n",
              "3    0.442391    0.010453       0.071951        0.150394  0.079155   \n",
              "4   -0.774923   -0.024826      -0.100731       -0.149488  0.435352   \n",
              "5    0.446990   -0.001307      -0.273412        0.076293  0.435352   \n",
              "6    0.179349   -0.018293      -0.201462        0.075886  0.435352   \n",
              "7    0.440134   -0.006533      -0.071951        0.075485  0.435352   \n",
              "8   -0.211687    1.932528      -0.482069       -0.016809  0.118732   \n",
              "9    0.464135    0.062719       0.129511        0.095919  0.118732   \n",
              "10   0.203333    0.088852       0.021585        0.095277  0.118732   \n",
              "11   0.376699   -0.232583      -0.014390        0.094645  0.118732   \n",
              "12  -0.748158   -1.837143       1.144015        0.041697  0.079155   \n",
              "13   0.462394   -0.006533       0.021585        0.181558  0.079155   \n",
              "14   0.199694   -0.011760      -0.071951        0.179274  0.079155   \n",
              "15   0.374045   -0.007840       0.028780        0.177047  0.079155   \n",
              "16  -0.744154    0.013066       0.446094       -0.066491  0.000000   \n",
              "17   0.460926   -0.005227      -0.100731        0.197145  0.000000   \n",
              "18   0.189874   -0.031359      -0.035975        0.194455  0.000000   \n",
              "19   0.368125   -0.018293      -0.165486        0.191837  0.000000   \n",
              "20  -0.754545   -0.033973      -0.611580       -0.101973  0.039577   \n",
              "21   0.448458   -0.039199      -0.093536        0.184345  0.039577   \n",
              "22   0.185126   -0.015680      -0.014390        0.181991  0.039577   \n",
              "23   0.365010   -0.010453       0.043170        0.179696  0.039577   \n",
              "24  -1.310464   -1.658133      -0.992918       -0.144364 -0.039577   \n",
              "25   0.890954    1.302725       0.510849        0.124931 -0.039577   \n",
              "26   0.259933    0.233889       0.388533        0.123846 -0.039577   \n",
              "27   0.429784    0.205143       0.316583        0.122779 -0.039577   \n",
              "28  -0.322282    3.548848       3.266557        0.106282 -0.158310   \n",
              "29   0.390887   -1.895942      -0.748286        0.285032 -0.158310   \n",
              "30   0.159234   -0.356714      -0.402923        0.279443 -0.158310   \n",
              "31   0.417791   -0.041813      -0.223047        0.274068 -0.158310   \n",
              "32  -0.765833   -1.469976      -1.014503        0.268897 -0.158310   \n",
              "\n",
              "    coal_cspt_lg  gas_cspt_lg  coal_cspt_yoy  oil_cspt_yoy  \n",
              "0      -0.812216     0.016214      -0.278887     -0.087727  \n",
              "1       0.241853     0.102184      -0.354947     -0.175455  \n",
              "2       0.234230     0.100922      -0.348609     -0.175455  \n",
              "3       0.226708     0.099691      -0.348609     -0.159504  \n",
              "4      -0.914274    -0.006638      -0.126767      1.036779  \n",
              "5      -0.117735     0.058745      -0.450022      0.598142  \n",
              "6      -0.122178     0.058308      -0.437345      0.598142  \n",
              "7      -0.126653     0.057877      -0.437345      0.582191  \n",
              "8      -0.376907     0.048396       0.665526     -0.199381  \n",
              "9       0.020256     0.080526       0.171135     -0.853349  \n",
              "10      0.015951     0.079681       0.171135     -0.829423  \n",
              "11      0.011650     0.078854       0.171135     -0.805498  \n",
              "12     -0.177927     0.145937       0.247195      0.223306  \n",
              "13      0.315212     0.182458       0.373962      0.382811  \n",
              "14      0.304983     0.177865       0.361285      0.374836  \n",
              "15      0.294926     0.173519       0.361285      0.366860  \n",
              "16     -0.569650     0.084528      -0.494390     -0.853349  \n",
              "17      0.361669     0.158714       0.057045     -0.127604  \n",
              "18      0.349886     0.155514       0.057045     -0.135579  \n",
              "19      0.338328     0.152448       0.057045     -0.135579  \n",
              "20     -0.639840     0.024540      -0.088737     -0.095703  \n",
              "21      0.372474     0.107166       0.012677      0.039876  \n",
              "22      0.362572     0.105799       0.012677      0.031901  \n",
              "23      0.352863     0.104467       0.019015      0.039876  \n",
              "24     -0.708369     0.009509      -0.088737     -0.462563  \n",
              "25      0.244445     0.087248      -0.158458     -0.558266  \n",
              "26      0.239821     0.086316      -0.152120     -0.550290  \n",
              "27      0.235257     0.085403      -0.152120     -0.534340  \n",
              "28      0.198344     0.092195       1.153578      1.108556  \n",
              "29      0.830675     0.143324       0.754262      0.590167  \n",
              "30      0.810249     0.140831       0.741586      0.566241  \n",
              "31      0.790580     0.138425       0.728909      0.542315  \n",
              "32      0.778385     0.133954       0.728909      0.542315  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9dae1844-71bf-42e0-a347-50a79f23864f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gdp_cn_lg</th>\n",
              "      <th>gdp_cn_yoy</th>\n",
              "      <th>export_gr_yoy</th>\n",
              "      <th>energy_cspt_lg</th>\n",
              "      <th>oil_rt</th>\n",
              "      <th>coal_cspt_lg</th>\n",
              "      <th>gas_cspt_lg</th>\n",
              "      <th>coal_cspt_yoy</th>\n",
              "      <th>oil_cspt_yoy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.766935</td>\n",
              "      <td>-0.023520</td>\n",
              "      <td>-0.813042</td>\n",
              "      <td>-0.144543</td>\n",
              "      <td>0.079155</td>\n",
              "      <td>-0.812216</td>\n",
              "      <td>0.016214</td>\n",
              "      <td>-0.278887</td>\n",
              "      <td>-0.087727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.447357</td>\n",
              "      <td>0.011760</td>\n",
              "      <td>0.309388</td>\n",
              "      <td>0.153637</td>\n",
              "      <td>0.079155</td>\n",
              "      <td>0.241853</td>\n",
              "      <td>0.102184</td>\n",
              "      <td>-0.354947</td>\n",
              "      <td>-0.175455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.184807</td>\n",
              "      <td>-0.048346</td>\n",
              "      <td>0.302193</td>\n",
              "      <td>0.151998</td>\n",
              "      <td>0.079155</td>\n",
              "      <td>0.234230</td>\n",
              "      <td>0.100922</td>\n",
              "      <td>-0.348609</td>\n",
              "      <td>-0.175455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.442391</td>\n",
              "      <td>0.010453</td>\n",
              "      <td>0.071951</td>\n",
              "      <td>0.150394</td>\n",
              "      <td>0.079155</td>\n",
              "      <td>0.226708</td>\n",
              "      <td>0.099691</td>\n",
              "      <td>-0.348609</td>\n",
              "      <td>-0.159504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.774923</td>\n",
              "      <td>-0.024826</td>\n",
              "      <td>-0.100731</td>\n",
              "      <td>-0.149488</td>\n",
              "      <td>0.435352</td>\n",
              "      <td>-0.914274</td>\n",
              "      <td>-0.006638</td>\n",
              "      <td>-0.126767</td>\n",
              "      <td>1.036779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.446990</td>\n",
              "      <td>-0.001307</td>\n",
              "      <td>-0.273412</td>\n",
              "      <td>0.076293</td>\n",
              "      <td>0.435352</td>\n",
              "      <td>-0.117735</td>\n",
              "      <td>0.058745</td>\n",
              "      <td>-0.450022</td>\n",
              "      <td>0.598142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.179349</td>\n",
              "      <td>-0.018293</td>\n",
              "      <td>-0.201462</td>\n",
              "      <td>0.075886</td>\n",
              "      <td>0.435352</td>\n",
              "      <td>-0.122178</td>\n",
              "      <td>0.058308</td>\n",
              "      <td>-0.437345</td>\n",
              "      <td>0.598142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.440134</td>\n",
              "      <td>-0.006533</td>\n",
              "      <td>-0.071951</td>\n",
              "      <td>0.075485</td>\n",
              "      <td>0.435352</td>\n",
              "      <td>-0.126653</td>\n",
              "      <td>0.057877</td>\n",
              "      <td>-0.437345</td>\n",
              "      <td>0.582191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.211687</td>\n",
              "      <td>1.932528</td>\n",
              "      <td>-0.482069</td>\n",
              "      <td>-0.016809</td>\n",
              "      <td>0.118732</td>\n",
              "      <td>-0.376907</td>\n",
              "      <td>0.048396</td>\n",
              "      <td>0.665526</td>\n",
              "      <td>-0.199381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.464135</td>\n",
              "      <td>0.062719</td>\n",
              "      <td>0.129511</td>\n",
              "      <td>0.095919</td>\n",
              "      <td>0.118732</td>\n",
              "      <td>0.020256</td>\n",
              "      <td>0.080526</td>\n",
              "      <td>0.171135</td>\n",
              "      <td>-0.853349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.203333</td>\n",
              "      <td>0.088852</td>\n",
              "      <td>0.021585</td>\n",
              "      <td>0.095277</td>\n",
              "      <td>0.118732</td>\n",
              "      <td>0.015951</td>\n",
              "      <td>0.079681</td>\n",
              "      <td>0.171135</td>\n",
              "      <td>-0.829423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.376699</td>\n",
              "      <td>-0.232583</td>\n",
              "      <td>-0.014390</td>\n",
              "      <td>0.094645</td>\n",
              "      <td>0.118732</td>\n",
              "      <td>0.011650</td>\n",
              "      <td>0.078854</td>\n",
              "      <td>0.171135</td>\n",
              "      <td>-0.805498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>-0.748158</td>\n",
              "      <td>-1.837143</td>\n",
              "      <td>1.144015</td>\n",
              "      <td>0.041697</td>\n",
              "      <td>0.079155</td>\n",
              "      <td>-0.177927</td>\n",
              "      <td>0.145937</td>\n",
              "      <td>0.247195</td>\n",
              "      <td>0.223306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.462394</td>\n",
              "      <td>-0.006533</td>\n",
              "      <td>0.021585</td>\n",
              "      <td>0.181558</td>\n",
              "      <td>0.079155</td>\n",
              "      <td>0.315212</td>\n",
              "      <td>0.182458</td>\n",
              "      <td>0.373962</td>\n",
              "      <td>0.382811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.199694</td>\n",
              "      <td>-0.011760</td>\n",
              "      <td>-0.071951</td>\n",
              "      <td>0.179274</td>\n",
              "      <td>0.079155</td>\n",
              "      <td>0.304983</td>\n",
              "      <td>0.177865</td>\n",
              "      <td>0.361285</td>\n",
              "      <td>0.374836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.374045</td>\n",
              "      <td>-0.007840</td>\n",
              "      <td>0.028780</td>\n",
              "      <td>0.177047</td>\n",
              "      <td>0.079155</td>\n",
              "      <td>0.294926</td>\n",
              "      <td>0.173519</td>\n",
              "      <td>0.361285</td>\n",
              "      <td>0.366860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-0.744154</td>\n",
              "      <td>0.013066</td>\n",
              "      <td>0.446094</td>\n",
              "      <td>-0.066491</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.569650</td>\n",
              "      <td>0.084528</td>\n",
              "      <td>-0.494390</td>\n",
              "      <td>-0.853349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.460926</td>\n",
              "      <td>-0.005227</td>\n",
              "      <td>-0.100731</td>\n",
              "      <td>0.197145</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.361669</td>\n",
              "      <td>0.158714</td>\n",
              "      <td>0.057045</td>\n",
              "      <td>-0.127604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.189874</td>\n",
              "      <td>-0.031359</td>\n",
              "      <td>-0.035975</td>\n",
              "      <td>0.194455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.349886</td>\n",
              "      <td>0.155514</td>\n",
              "      <td>0.057045</td>\n",
              "      <td>-0.135579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.368125</td>\n",
              "      <td>-0.018293</td>\n",
              "      <td>-0.165486</td>\n",
              "      <td>0.191837</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.338328</td>\n",
              "      <td>0.152448</td>\n",
              "      <td>0.057045</td>\n",
              "      <td>-0.135579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>-0.754545</td>\n",
              "      <td>-0.033973</td>\n",
              "      <td>-0.611580</td>\n",
              "      <td>-0.101973</td>\n",
              "      <td>0.039577</td>\n",
              "      <td>-0.639840</td>\n",
              "      <td>0.024540</td>\n",
              "      <td>-0.088737</td>\n",
              "      <td>-0.095703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.448458</td>\n",
              "      <td>-0.039199</td>\n",
              "      <td>-0.093536</td>\n",
              "      <td>0.184345</td>\n",
              "      <td>0.039577</td>\n",
              "      <td>0.372474</td>\n",
              "      <td>0.107166</td>\n",
              "      <td>0.012677</td>\n",
              "      <td>0.039876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.185126</td>\n",
              "      <td>-0.015680</td>\n",
              "      <td>-0.014390</td>\n",
              "      <td>0.181991</td>\n",
              "      <td>0.039577</td>\n",
              "      <td>0.362572</td>\n",
              "      <td>0.105799</td>\n",
              "      <td>0.012677</td>\n",
              "      <td>0.031901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.365010</td>\n",
              "      <td>-0.010453</td>\n",
              "      <td>0.043170</td>\n",
              "      <td>0.179696</td>\n",
              "      <td>0.039577</td>\n",
              "      <td>0.352863</td>\n",
              "      <td>0.104467</td>\n",
              "      <td>0.019015</td>\n",
              "      <td>0.039876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>-1.310464</td>\n",
              "      <td>-1.658133</td>\n",
              "      <td>-0.992918</td>\n",
              "      <td>-0.144364</td>\n",
              "      <td>-0.039577</td>\n",
              "      <td>-0.708369</td>\n",
              "      <td>0.009509</td>\n",
              "      <td>-0.088737</td>\n",
              "      <td>-0.462563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.890954</td>\n",
              "      <td>1.302725</td>\n",
              "      <td>0.510849</td>\n",
              "      <td>0.124931</td>\n",
              "      <td>-0.039577</td>\n",
              "      <td>0.244445</td>\n",
              "      <td>0.087248</td>\n",
              "      <td>-0.158458</td>\n",
              "      <td>-0.558266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.259933</td>\n",
              "      <td>0.233889</td>\n",
              "      <td>0.388533</td>\n",
              "      <td>0.123846</td>\n",
              "      <td>-0.039577</td>\n",
              "      <td>0.239821</td>\n",
              "      <td>0.086316</td>\n",
              "      <td>-0.152120</td>\n",
              "      <td>-0.550290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.429784</td>\n",
              "      <td>0.205143</td>\n",
              "      <td>0.316583</td>\n",
              "      <td>0.122779</td>\n",
              "      <td>-0.039577</td>\n",
              "      <td>0.235257</td>\n",
              "      <td>0.085403</td>\n",
              "      <td>-0.152120</td>\n",
              "      <td>-0.534340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>-0.322282</td>\n",
              "      <td>3.548848</td>\n",
              "      <td>3.266557</td>\n",
              "      <td>0.106282</td>\n",
              "      <td>-0.158310</td>\n",
              "      <td>0.198344</td>\n",
              "      <td>0.092195</td>\n",
              "      <td>1.153578</td>\n",
              "      <td>1.108556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.390887</td>\n",
              "      <td>-1.895942</td>\n",
              "      <td>-0.748286</td>\n",
              "      <td>0.285032</td>\n",
              "      <td>-0.158310</td>\n",
              "      <td>0.830675</td>\n",
              "      <td>0.143324</td>\n",
              "      <td>0.754262</td>\n",
              "      <td>0.590167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.159234</td>\n",
              "      <td>-0.356714</td>\n",
              "      <td>-0.402923</td>\n",
              "      <td>0.279443</td>\n",
              "      <td>-0.158310</td>\n",
              "      <td>0.810249</td>\n",
              "      <td>0.140831</td>\n",
              "      <td>0.741586</td>\n",
              "      <td>0.566241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.417791</td>\n",
              "      <td>-0.041813</td>\n",
              "      <td>-0.223047</td>\n",
              "      <td>0.274068</td>\n",
              "      <td>-0.158310</td>\n",
              "      <td>0.790580</td>\n",
              "      <td>0.138425</td>\n",
              "      <td>0.728909</td>\n",
              "      <td>0.542315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>-0.765833</td>\n",
              "      <td>-1.469976</td>\n",
              "      <td>-1.014503</td>\n",
              "      <td>0.268897</td>\n",
              "      <td>-0.158310</td>\n",
              "      <td>0.778385</td>\n",
              "      <td>0.133954</td>\n",
              "      <td>0.728909</td>\n",
              "      <td>0.542315</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dae1844-71bf-42e0-a347-50a79f23864f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9dae1844-71bf-42e0-a347-50a79f23864f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9dae1844-71bf-42e0-a347-50a79f23864f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ],
      "source": [
        "X_dif2 = pd.DataFrame(X_dif1)\n",
        "X_dif2.index = ['gdp_cn_lg', 'gdp_cn_yoy','export_gr_yoy','energy_cspt_lg','oil_rt','coal_cspt_lg','gas_cspt_lg','coal_cspt_yoy','oil_cspt_yoy']\n",
        "X_dif = X_dif2.T\n",
        "# 对所有指标进行一阶差分\n",
        "X_dif"
      ],
      "id": "eepPMkukRjue"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmIr6UTrRjuf"
      },
      "source": [
        "## 4. 协整关系检验"
      ],
      "id": "VmIr6UTrRjuf"
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "aLL6KxE0Rjuf",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d92c5abf-3118-4708-8a1c-ed6a6cf5e8e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               fubon_npl gdp_cn_lg gdp_cn_yoy export_gr_yoy energy_cspt_lg  \\\n",
            "fubon_npl            0.0  0.900149   0.985828      0.912006       0.979375   \n",
            "gdp_cn_lg            NaN       0.0   0.979693      0.544569       0.045824   \n",
            "gdp_cn_yoy           NaN       NaN        0.0      0.311649       0.350053   \n",
            "export_gr_yoy        NaN       NaN        NaN           0.0       0.001157   \n",
            "energy_cspt_lg       NaN       NaN        NaN           NaN            0.0   \n",
            "oil_rt               NaN       NaN        NaN           NaN            NaN   \n",
            "coal_cspt_lg         NaN       NaN        NaN           NaN            NaN   \n",
            "gas_cspt_lg          NaN       NaN        NaN           NaN            NaN   \n",
            "coal_cspt_yoy        NaN       NaN        NaN           NaN            NaN   \n",
            "oil_cspt_yoy         NaN       NaN        NaN           NaN            NaN   \n",
            "\n",
            "                  oil_rt coal_cspt_lg gas_cspt_lg coal_cspt_yoy oil_cspt_yoy  \n",
            "fubon_npl       0.984827     0.839491    0.982014      0.969527     0.932126  \n",
            "gdp_cn_lg       0.835705     0.188347     0.03397      0.652022          1.0  \n",
            "gdp_cn_yoy      0.360409      0.33845    0.345895       0.34768     0.368848  \n",
            "export_gr_yoy   0.647208     0.000722    0.198738      0.001373      0.51017  \n",
            "energy_cspt_lg  0.943233     0.447712     0.68746      0.042127     0.816966  \n",
            "oil_rt               0.0     0.544529    0.351489      0.081883      0.09424  \n",
            "coal_cspt_lg         NaN          0.0    0.803844      0.090898     0.918744  \n",
            "gas_cspt_lg          NaN          NaN         0.0      0.125395     0.677627  \n",
            "coal_cspt_yoy        NaN          NaN         NaN           0.0     0.875655  \n",
            "oil_cspt_yoy         NaN          NaN         NaN           NaN          0.0  \n"
          ]
        }
      ],
      "source": [
        "# 定义协整检验结果输出形式\n",
        "data_tmp = pd.merge(Y,X,how = 'left',left_index=True,right_index=True)\n",
        "coint_result = pd.DataFrame(index =[data_tmp.columns],columns=[data_tmp.columns])\n",
        "# 记录变量间协整检验 p-value\n",
        "# H0为非协整，p-value越小，拒绝H0证据越充分\n",
        "for i in range(0,data_tmp.columns.size):\n",
        "    for j in range(i,data_tmp.columns.size):\n",
        "        coint_result.iloc[i,j] = coint(data_tmp.iloc[:,i],data_tmp.iloc[:,j],trend='nc',autolag='aic')[1]\n",
        "\n",
        "print(coint_result)\n",
        "# 除了dd_rate,其余变量和npl没有两两之间的协整关系"
      ],
      "id": "aLL6KxE0Rjuf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c78bI8K-Rjug"
      },
      "source": [
        "## 5. 建立VAR模型"
      ],
      "id": "c78bI8K-Rjug"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiSAwAEiRjug"
      },
      "source": [
        "### 5.1 模型建立"
      ],
      "id": "eiSAwAEiRjug"
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "ZqmkR_ziRjug",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33b25554-a31c-44f4-d640-905537e1f5e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Summary of Regression Results   \n",
              "==================================\n",
              "Model:                         VAR\n",
              "Method:                        OLS\n",
              "Date:           Wed, 24, Aug, 2022\n",
              "Time:                     05:37:13\n",
              "--------------------------------------------------------------------\n",
              "No. of Equations:         9.00000    BIC:                   -33.1238\n",
              "Nobs:                     31.0000    HQIC:                  -38.4553\n",
              "Log likelihood:           411.140    FPE:                9.24894e-18\n",
              "AIC:                     -41.0338    Det(Omega_mle):     1.25204e-19\n",
              "--------------------------------------------------------------------\n",
              "Results for equation gdp_cn_lg\n",
              "====================================================================================\n",
              "                       coefficient       std. error           t-stat            prob\n",
              "------------------------------------------------------------------------------------\n",
              "const                     1.236596         1.003575            1.232           0.218\n",
              "L1.gdp_cn_lg             -3.402918         1.392157           -2.444           0.015\n",
              "L1.gdp_cn_yoy             1.064255         0.557812            1.908           0.056\n",
              "L1.export_gr_yoy         -0.688768         0.589610           -1.168           0.243\n",
              "L1.energy_cspt_lg       -54.869912        38.100269           -1.440           0.150\n",
              "L1.oil_rt                10.810729         6.864431            1.575           0.115\n",
              "L1.coal_cspt_lg          17.735831        11.045653            1.606           0.108\n",
              "L1.gas_cspt_lg           19.926098        14.214413            1.402           0.161\n",
              "L1.coal_cspt_yoy         -1.059960         1.171337           -0.905           0.366\n",
              "L1.oil_cspt_yoy          -0.750252         0.977525           -0.768           0.443\n",
              "L2.gdp_cn_lg              0.535014         0.919709            0.582           0.561\n",
              "L2.gdp_cn_yoy            -0.111823         0.222163           -0.503           0.615\n",
              "L2.export_gr_yoy          0.351955         0.195473            1.801           0.072\n",
              "L2.energy_cspt_lg        27.207941        41.025845            0.663           0.507\n",
              "L2.oil_rt                -4.776372         5.850959           -0.816           0.414\n",
              "L2.coal_cspt_lg          -8.588927        11.095841           -0.774           0.439\n",
              "L2.gas_cspt_lg          -10.810725        13.211281           -0.818           0.413\n",
              "L2.coal_cspt_yoy          0.992215         1.069905            0.927           0.354\n",
              "L2.oil_cspt_yoy          -0.069987         0.977821           -0.072           0.943\n",
              "====================================================================================\n",
              "\n",
              "Results for equation gdp_cn_yoy\n",
              "====================================================================================\n",
              "                       coefficient       std. error           t-stat            prob\n",
              "------------------------------------------------------------------------------------\n",
              "const                     4.238492         3.030506            1.399           0.162\n",
              "L1.gdp_cn_lg              0.257565         4.203911            0.061           0.951\n",
              "L1.gdp_cn_yoy            -0.095344         1.684432           -0.057           0.955\n",
              "L1.export_gr_yoy         -0.378589         1.780451           -0.213           0.832\n",
              "L1.energy_cspt_lg       -66.437459       115.051794           -0.577           0.564\n",
              "L1.oil_rt                 5.962762        20.728597            0.288           0.774\n",
              "L1.coal_cspt_lg          16.429822        33.354677            0.493           0.622\n",
              "L1.gas_cspt_lg           24.672840        42.923418            0.575           0.565\n",
              "L1.coal_cspt_yoy         -0.523936         3.537098           -0.148           0.882\n",
              "L1.oil_cspt_yoy          -0.515289         2.951843           -0.175           0.861\n",
              "L2.gdp_cn_lg             -0.256154         2.777256           -0.092           0.927\n",
              "L2.gdp_cn_yoy             0.250795         0.670868            0.374           0.709\n",
              "L2.export_gr_yoy         -0.132755         0.590271           -0.225           0.822\n",
              "L2.energy_cspt_lg       -21.857292       123.886189           -0.176           0.860\n",
              "L2.oil_rt                 2.257916        17.668206            0.128           0.898\n",
              "L2.coal_cspt_lg           6.513895        33.506233            0.194           0.846\n",
              "L2.gas_cspt_lg            3.715520        39.894250            0.093           0.926\n",
              "L2.coal_cspt_yoy         -1.293904         3.230804           -0.400           0.689\n",
              "L2.oil_cspt_yoy           0.156319         2.952737            0.053           0.958\n",
              "====================================================================================\n",
              "\n",
              "Results for equation export_gr_yoy\n",
              "====================================================================================\n",
              "                       coefficient       std. error           t-stat            prob\n",
              "------------------------------------------------------------------------------------\n",
              "const                     3.353970         2.072147            1.619           0.106\n",
              "L1.gdp_cn_lg              1.777614         2.874477            0.618           0.536\n",
              "L1.gdp_cn_yoy            -1.111436         1.151752           -0.965           0.335\n",
              "L1.export_gr_yoy          0.656341         1.217406            0.539           0.590\n",
              "L1.energy_cspt_lg        -7.988099        78.668128           -0.102           0.919\n",
              "L1.oil_rt                 0.249590        14.173442            0.018           0.986\n",
              "L1.coal_cspt_lg           1.210586        22.806685            0.053           0.958\n",
              "L1.gas_cspt_lg          -12.773971        29.349433           -0.435           0.663\n",
              "L1.coal_cspt_yoy          1.940216         2.418536            0.802           0.422\n",
              "L1.oil_cspt_yoy          -0.993637         2.018360           -0.492           0.623\n",
              "L2.gdp_cn_lg              0.727075         1.898984            0.383           0.702\n",
              "L2.gdp_cn_yoy            -0.098370         0.458715           -0.214           0.830\n",
              "L2.export_gr_yoy         -0.154190         0.403605           -0.382           0.702\n",
              "L2.energy_cspt_lg       -51.382454        84.708758           -0.607           0.544\n",
              "L2.oil_rt                 2.791573        12.080860            0.231           0.817\n",
              "L2.coal_cspt_lg          11.746258        22.910313            0.513           0.608\n",
              "L2.gas_cspt_lg           27.219970        27.278201            0.998           0.318\n",
              "L2.coal_cspt_yoy         -1.978486         2.209103           -0.896           0.370\n",
              "L2.oil_cspt_yoy           0.533630         2.018972            0.264           0.792\n",
              "====================================================================================\n",
              "\n",
              "Results for equation energy_cspt_lg\n",
              "====================================================================================\n",
              "                       coefficient       std. error           t-stat            prob\n",
              "------------------------------------------------------------------------------------\n",
              "const                     0.480657         0.268094            1.793           0.073\n",
              "L1.gdp_cn_lg             -0.553177         0.371900           -1.487           0.137\n",
              "L1.gdp_cn_yoy             0.140444         0.149014            0.942           0.346\n",
              "L1.export_gr_yoy         -0.167294         0.157508           -1.062           0.288\n",
              "L1.energy_cspt_lg         3.937705        10.178074            0.387           0.699\n",
              "L1.oil_rt                -0.289130         1.833758           -0.158           0.875\n",
              "L1.coal_cspt_lg          -0.465026         2.950726           -0.158           0.875\n",
              "L1.gas_cspt_lg           -0.909506         3.797226           -0.240           0.811\n",
              "L1.coal_cspt_yoy         -0.258900         0.312910           -0.827           0.408\n",
              "L1.oil_cspt_yoy           0.133254         0.261135            0.510           0.610\n",
              "L2.gdp_cn_lg              0.040169         0.245690            0.163           0.870\n",
              "L2.gdp_cn_yoy            -0.008859         0.059348           -0.149           0.881\n",
              "L2.export_gr_yoy          0.029713         0.052218            0.569           0.569\n",
              "L2.energy_cspt_lg        -9.906256        10.959610           -0.904           0.366\n",
              "L2.oil_rt                 1.156937         1.563020            0.740           0.459\n",
              "L2.coal_cspt_lg           2.361886         2.964134            0.797           0.426\n",
              "L2.gas_cspt_lg            1.966096         3.529251            0.557           0.577\n",
              "L2.coal_cspt_yoy          0.355379         0.285814            1.243           0.214\n",
              "L2.oil_cspt_yoy          -0.240720         0.261214           -0.922           0.357\n",
              "====================================================================================\n",
              "\n",
              "Results for equation oil_rt\n",
              "====================================================================================\n",
              "                       coefficient       std. error           t-stat            prob\n",
              "------------------------------------------------------------------------------------\n",
              "const                    -0.325669         0.323422           -1.007           0.314\n",
              "L1.gdp_cn_lg             -0.206850         0.448650           -0.461           0.645\n",
              "L1.gdp_cn_yoy             0.183819         0.179766            1.023           0.307\n",
              "L1.export_gr_yoy         -0.103406         0.190013           -0.544           0.586\n",
              "L1.energy_cspt_lg        -6.061029        12.278556           -0.494           0.622\n",
              "L1.oil_rt                 1.943950         2.212197            0.879           0.380\n",
              "L1.coal_cspt_lg           1.550737         3.559677            0.436           0.663\n",
              "L1.gas_cspt_lg            5.253022         4.580872            1.147           0.251\n",
              "L1.coal_cspt_yoy         -0.247107         0.377486           -0.655           0.513\n",
              "L1.oil_cspt_yoy          -0.057122         0.315027           -0.181           0.856\n",
              "L2.gdp_cn_lg              0.011981         0.296394            0.040           0.968\n",
              "L2.gdp_cn_yoy            -0.020470         0.071596           -0.286           0.775\n",
              "L2.export_gr_yoy          0.080791         0.062995            1.282           0.200\n",
              "L2.energy_cspt_lg        11.899039        13.221380            0.900           0.368\n",
              "L2.oil_rt                -1.594232         1.885586           -0.845           0.398\n",
              "L2.coal_cspt_lg          -2.895894         3.575852           -0.810           0.418\n",
              "L2.gas_cspt_lg           -6.425185         4.257594           -1.509           0.131\n",
              "L2.coal_cspt_yoy          0.151636         0.344798            0.440           0.660\n",
              "L2.oil_cspt_yoy           0.036455         0.315122            0.116           0.908\n",
              "====================================================================================\n",
              "\n",
              "Results for equation coal_cspt_lg\n",
              "====================================================================================\n",
              "                       coefficient       std. error           t-stat            prob\n",
              "------------------------------------------------------------------------------------\n",
              "const                     1.705497         0.944778            1.805           0.071\n",
              "L1.gdp_cn_lg             -1.913948         1.310594           -1.460           0.144\n",
              "L1.gdp_cn_yoy             0.476621         0.525132            0.908           0.364\n",
              "L1.export_gr_yoy         -0.581531         0.555066           -1.048           0.295\n",
              "L1.energy_cspt_lg        11.499910        35.868079            0.321           0.749\n",
              "L1.oil_rt                -1.244285         6.462263           -0.193           0.847\n",
              "L1.coal_cspt_lg          -0.963529        10.398518           -0.093           0.926\n",
              "L1.gas_cspt_lg           -3.770654        13.381630           -0.282           0.778\n",
              "L1.coal_cspt_yoy         -0.904042         1.102711           -0.820           0.412\n",
              "L1.oil_cspt_yoy           0.494849         0.920255            0.538           0.591\n",
              "L2.gdp_cn_lg              0.108354         0.865826            0.125           0.900\n",
              "L2.gdp_cn_yoy            -0.021942         0.209147           -0.105           0.916\n",
              "L2.export_gr_yoy          0.090305         0.184021            0.491           0.624\n",
              "L2.energy_cspt_lg       -36.140247        38.622254           -0.936           0.349\n",
              "L2.oil_rt                 4.344432         5.508168            0.789           0.430\n",
              "L2.coal_cspt_lg           8.690139        10.445767            0.832           0.405\n",
              "L2.gas_cspt_lg            7.445957        12.437269            0.599           0.549\n",
              "L2.coal_cspt_yoy          1.241564         1.007222            1.233           0.218\n",
              "L2.oil_cspt_yoy          -0.867355         0.920533           -0.942           0.346\n",
              "====================================================================================\n",
              "\n",
              "Results for equation gas_cspt_lg\n",
              "====================================================================================\n",
              "                       coefficient       std. error           t-stat            prob\n",
              "------------------------------------------------------------------------------------\n",
              "const                     0.176724         0.110483            1.600           0.110\n",
              "L1.gdp_cn_lg             -0.075416         0.153262           -0.492           0.623\n",
              "L1.gdp_cn_yoy            -0.020365         0.061409           -0.332           0.740\n",
              "L1.export_gr_yoy         -0.009933         0.064910           -0.153           0.878\n",
              "L1.energy_cspt_lg         3.759960         4.194444            0.896           0.370\n",
              "L1.oil_rt                -0.482015         0.755703           -0.638           0.524\n",
              "L1.coal_cspt_lg          -0.906467         1.216012           -0.745           0.456\n",
              "L1.gas_cspt_lg           -1.260892         1.564859           -0.806           0.420\n",
              "L1.coal_cspt_yoy          0.012899         0.128952            0.100           0.920\n",
              "L1.oil_cspt_yoy           0.045478         0.107615            0.423           0.673\n",
              "L2.gdp_cn_lg              0.044511         0.101250            0.440           0.660\n",
              "L2.gdp_cn_yoy            -0.014652         0.024458           -0.599           0.549\n",
              "L2.export_gr_yoy          0.002587         0.021520            0.120           0.904\n",
              "L2.energy_cspt_lg        -5.709014         4.516519           -1.264           0.206\n",
              "L2.oil_rt                 0.644560         0.644130            1.001           0.317\n",
              "L2.coal_cspt_lg           1.329562         1.221537            1.088           0.276\n",
              "L2.gas_cspt_lg            2.111942         1.454425            1.452           0.146\n",
              "L2.coal_cspt_yoy          0.066137         0.117785            0.562           0.574\n",
              "L2.oil_cspt_yoy          -0.068572         0.107648           -0.637           0.524\n",
              "====================================================================================\n",
              "\n",
              "Results for equation coal_cspt_yoy\n",
              "====================================================================================\n",
              "                       coefficient       std. error           t-stat            prob\n",
              "------------------------------------------------------------------------------------\n",
              "const                     1.398989         1.110099            1.260           0.208\n",
              "L1.gdp_cn_lg              0.886618         1.539927            0.576           0.565\n",
              "L1.gdp_cn_yoy            -0.288965         0.617021           -0.468           0.640\n",
              "L1.export_gr_yoy         -0.195643         0.652194           -0.300           0.764\n",
              "L1.energy_cspt_lg        50.722832        42.144405            1.204           0.229\n",
              "L1.oil_rt               -10.777603         7.593053           -1.419           0.156\n",
              "L1.coal_cspt_lg         -14.373019        12.218088           -1.176           0.239\n",
              "L1.gas_cspt_lg          -16.583994        15.723196           -1.055           0.292\n",
              "L1.coal_cspt_yoy         -0.304470         1.295668           -0.235           0.814\n",
              "L1.oil_cspt_yoy           1.312087         1.081284            1.213           0.225\n",
              "L2.gdp_cn_lg             -0.055933         1.017331           -0.055           0.956\n",
              "L2.gdp_cn_yoy            -0.014970         0.245745           -0.061           0.951\n",
              "L2.export_gr_yoy          0.002280         0.216221            0.011           0.992\n",
              "L2.energy_cspt_lg       -63.791872        45.380515           -1.406           0.160\n",
              "L2.oil_rt                10.740313         6.472007            1.660           0.097\n",
              "L2.coal_cspt_lg          17.264510        12.273605            1.407           0.160\n",
              "L2.gas_cspt_lg           14.211003        14.613587            0.972           0.331\n",
              "L2.coal_cspt_yoy          0.926854         1.183470            0.783           0.434\n",
              "L2.oil_cspt_yoy          -1.214707         1.081612           -1.123           0.261\n",
              "====================================================================================\n",
              "\n",
              "Results for equation oil_cspt_yoy\n",
              "====================================================================================\n",
              "                       coefficient       std. error           t-stat            prob\n",
              "------------------------------------------------------------------------------------\n",
              "const                     0.786853         1.582663            0.497           0.619\n",
              "L1.gdp_cn_lg              0.511318         2.195467            0.233           0.816\n",
              "L1.gdp_cn_yoy             0.074803         0.879684            0.085           0.932\n",
              "L1.export_gr_yoy         -0.486643         0.929830           -0.523           0.601\n",
              "L1.energy_cspt_lg        55.434346        60.085110            0.923           0.356\n",
              "L1.oil_rt               -10.624825        10.825386           -0.981           0.326\n",
              "L1.coal_cspt_lg         -15.861659        17.419280           -0.911           0.363\n",
              "L1.gas_cspt_lg          -10.036127        22.416498           -0.448           0.654\n",
              "L1.coal_cspt_yoy         -1.848595         1.847228           -1.001           0.317\n",
              "L1.oil_cspt_yoy           2.131227         1.541582            1.382           0.167\n",
              "L2.gdp_cn_lg              0.197977         1.450405            0.136           0.891\n",
              "L2.gdp_cn_yoy            -0.176247         0.350357           -0.503           0.615\n",
              "L2.export_gr_yoy          0.298766         0.308266            0.969           0.332\n",
              "L2.energy_cspt_lg       -53.049394        64.698820           -0.820           0.412\n",
              "L2.oil_rt                 8.190551         9.227115            0.888           0.375\n",
              "L2.coal_cspt_lg          14.751548        17.498429            0.843           0.399\n",
              "L2.gas_cspt_lg            2.462844        20.834533            0.118           0.906\n",
              "L2.coal_cspt_yoy          1.569405         1.687268            0.930           0.352\n",
              "L2.oil_cspt_yoy          -1.402699         1.542049           -0.910           0.363\n",
              "====================================================================================\n",
              "\n",
              "Correlation matrix of residuals\n",
              "                  gdp_cn_lg  gdp_cn_yoy  export_gr_yoy  energy_cspt_lg    oil_rt  coal_cspt_lg  gas_cspt_lg  coal_cspt_yoy  oil_cspt_yoy\n",
              "gdp_cn_lg          1.000000    0.455398       0.048327        0.705669 -0.227624      0.693999     0.553096       0.411494     -0.046258\n",
              "gdp_cn_yoy         0.455398    1.000000       0.583974        0.269164 -0.362154      0.287386     0.079593       0.759166      0.222287\n",
              "export_gr_yoy      0.048327    0.583974       1.000000        0.237837 -0.070856      0.221823     0.270578       0.416664      0.645247\n",
              "energy_cspt_lg     0.705669    0.269164       0.237837        1.000000 -0.331739      0.993615     0.934255       0.531402      0.217888\n",
              "oil_rt            -0.227624   -0.362154      -0.070856       -0.331739  1.000000     -0.427854    -0.316735      -0.390020      0.479808\n",
              "coal_cspt_lg       0.693999    0.287386       0.221823        0.993615 -0.427854      1.000000     0.929051       0.559641      0.163721\n",
              "gas_cspt_lg        0.553096    0.079593       0.270578        0.934255 -0.316735      0.929051     1.000000       0.436734      0.273240\n",
              "coal_cspt_yoy      0.411494    0.759166       0.416664        0.531402 -0.390020      0.559641     0.436734       1.000000      0.419043\n",
              "oil_cspt_yoy      -0.046258    0.222287       0.645247        0.217888  0.479808      0.163721     0.273240       0.419043      1.000000\n",
              "\n"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "# 使用入模X的一阶差分建立向量自回归模型\n",
        "# 建立VAR模型\n",
        "VARmodel = VAR(X_dif)\n",
        "VARresult = VARmodel.fit(maxlags=2,ic='aic') \n",
        "VARresult.summary()"
      ],
      "id": "ZqmkR_ziRjug"
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "aWfzc02uRjuh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4327812-6ae1-4834-fedf-bb0809fd8d35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "# 最优滞后阶数\n",
        "lag_order = VARresult.k_ar\n",
        "lag_order"
      ],
      "id": "aWfzc02uRjuh"
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "b7sPNsPFRjuh"
      },
      "outputs": [],
      "source": [
        "# 输出残差项\n",
        "resid = np.array(VARresult.resid)"
      ],
      "id": "b7sPNsPFRjuh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXHtjVYYRjui"
      },
      "source": [
        "### 5.2 模型稳定性检验：CUSUM检验"
      ],
      "id": "wXHtjVYYRjui"
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "4k8-ErVnRjui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6fc46e1-5be7-4d19-957e-6999b9014aa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1.1831793089053038, 0.12161385424909314, [(1, 1.63), (5, 1.36), (10, 1.22)])\n"
          ]
        }
      ],
      "source": [
        "# 模型稳定性检验：CUSUM检验\n",
        "# 原假设：无漂移（平稳），备择假设：有漂移（不平稳）\n",
        "result = statsmodels.stats.diagnostic.breaks_cusumolsresid(resid)\n",
        "print(result)\n",
        "# (1.351727608700142, 0.05175650227087939, [(1, 1.63), (5, 1.36), (10, 1.22)])\n",
        "# 可以在5%和1%的置信水平不拒绝原假设，VAR模型平稳"
      ],
      "id": "4k8-ErVnRjui"
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "M1C2RSOIMMTf"
      },
      "outputs": [],
      "source": [
        "#%% MONTE CARLO模拟轻度、中度、重度情景的X：\n",
        "# 提取残差项的方差协方差矩阵\n",
        "resid_cov = VARresult.summary().model.resid_corr\n",
        "# 对残差想的方差协方差矩阵做cholesky decomposition\n",
        "M = np.linalg.cholesky(resid_cov)\n",
        "# 验证分解正确 np.mat(M)*np.mat(M.T)-resid_cov"
      ],
      "id": "M1C2RSOIMMTf"
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "CJ9U2LxFMMTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de3f586-a207-4831-c579-2c53124fe823"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ],
      "source": [
        "# 入模变量个数\n",
        "N = X_dif.shape[1]\n",
        "N"
      ],
      "id": "CJ9U2LxFMMTg"
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "VF6o7j5JMMTh"
      },
      "outputs": [],
      "source": [
        "# VAR模型的截距项\n",
        "c = []\n",
        "for i in range(0,N):\n",
        "    c.extend([VARresult.summary().model.coefs_exog[i][0]])\n",
        "c = np.array(c).T"
      ],
      "id": "VF6o7j5JMMTh"
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "vm3x9SbbMMTh"
      },
      "outputs": [],
      "source": [
        "# 构造VAR模型系数估计值矩阵\n",
        "params = VARresult.summary().model.coefs #(3,10,10)\n",
        "params_tr_list = []   \n",
        "for i in range(0,N):\n",
        "    for j in range(0,lag_order):\n",
        "        if j == 0:\n",
        "            tmp = params[j][i] # lag 1 of equation 1\n",
        "        else:\n",
        "            tmp = np.hstack([tmp,params[j][i]])\n",
        "    params_tr_list.extend([tmp])\n",
        "        \n",
        "for i in range(0,len(params_tr_list)):\n",
        "    if i == 0:\n",
        "        params_tr = params_tr_list[0]\n",
        "    else:\n",
        "        params_tr = np.vstack((params_tr,params_tr_list[i]))"
      ],
      "id": "vm3x9SbbMMTh"
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "ozSCTPC4MMTh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "e17a6862-3bc4-4941-c9fc-af6910c199da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    gdp_cn_lg  gdp_cn_yoy  export_gr_yoy  energy_cspt_lg   oil_rt  \\\n",
              "31   0.417791   -0.041813      -0.223047        0.274068 -0.15831   \n",
              "32  -0.765833   -1.469976      -1.014503        0.268897 -0.15831   \n",
              "\n",
              "    coal_cspt_lg  gas_cspt_lg  coal_cspt_yoy  oil_cspt_yoy  \n",
              "31      0.790580     0.138425       0.728909      0.542315  \n",
              "32      0.778385     0.133954       0.728909      0.542315  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17e46fb5-63d4-4240-a57c-f7bc2c833d9e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gdp_cn_lg</th>\n",
              "      <th>gdp_cn_yoy</th>\n",
              "      <th>export_gr_yoy</th>\n",
              "      <th>energy_cspt_lg</th>\n",
              "      <th>oil_rt</th>\n",
              "      <th>coal_cspt_lg</th>\n",
              "      <th>gas_cspt_lg</th>\n",
              "      <th>coal_cspt_yoy</th>\n",
              "      <th>oil_cspt_yoy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.417791</td>\n",
              "      <td>-0.041813</td>\n",
              "      <td>-0.223047</td>\n",
              "      <td>0.274068</td>\n",
              "      <td>-0.15831</td>\n",
              "      <td>0.790580</td>\n",
              "      <td>0.138425</td>\n",
              "      <td>0.728909</td>\n",
              "      <td>0.542315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>-0.765833</td>\n",
              "      <td>-1.469976</td>\n",
              "      <td>-1.014503</td>\n",
              "      <td>0.268897</td>\n",
              "      <td>-0.15831</td>\n",
              "      <td>0.778385</td>\n",
              "      <td>0.133954</td>\n",
              "      <td>0.728909</td>\n",
              "      <td>0.542315</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17e46fb5-63d4-4240-a57c-f7bc2c833d9e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17e46fb5-63d4-4240-a57c-f7bc2c833d9e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17e46fb5-63d4-4240-a57c-f7bc2c833d9e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ],
      "source": [
        "# 截取X_dif最近lag_order期的变量\n",
        "X_dif_lag = X_dif.iloc[-lag_order:,:] #(3,10)\n",
        "# 准备初始的X_dif\n",
        "for j in range(0,lag_order):\n",
        "    if j == 0:\n",
        "        x_0 = np.array(X_dif_lag.iloc[-1-j,:])\n",
        "    else:\n",
        "        x_0 = np.hstack((x_0,np.array(X_dif_lag.iloc[-1-j,:])))\n",
        "X_dif_lag"
      ],
      "id": "ozSCTPC4MMTh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qZEkCoNRjuk"
      },
      "source": [
        "## 7. VECM模型"
      ],
      "id": "8qZEkCoNRjuk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87bGxa7iRjul"
      },
      "source": [
        "### 7.1 单变量滞后期与Y的相关性分析"
      ],
      "id": "87bGxa7iRjul"
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "xHvz7WQ6Rjul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d666f97-2ef1-475a-b228-602a88ca5b05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fubon_npl            1.000000\n",
            "gdp_cn_lg           -0.210084\n",
            "gdp_cn_yoy           0.021850\n",
            "export_gr_yoy       -0.265128\n",
            "energy_cspt_lg      -0.258976\n",
            "oil_rt               0.272359\n",
            "coal_cspt_lg        -0.772345\n",
            "gas_cspt_lg         -0.251337\n",
            "coal_cspt_yoy       -0.301933\n",
            "oil_cspt_yoy         0.262969\n",
            "L1_gdp_cn_lg        -0.246324\n",
            "L1_gdp_cn_yoy        0.074873\n",
            "L1_export_gr_yoy    -0.198228\n",
            "L1_energy_cspt_lg   -0.333890\n",
            "L1_oil_rt            0.076627\n",
            "L1_coal_cspt_lg     -0.765374\n",
            "L1_gas_cspt_lg      -0.334225\n",
            "L1_coal_cspt_yoy    -0.279602\n",
            "L1_oil_cspt_yoy      0.513412\n",
            "L2_gdp_cn_lg        -0.262463\n",
            "L2_gdp_cn_yoy        0.100632\n",
            "L2_export_gr_yoy    -0.130889\n",
            "L2_energy_cspt_lg   -0.357038\n",
            "L2_oil_rt           -0.058131\n",
            "L2_coal_cspt_lg     -0.745601\n",
            "L2_gas_cspt_lg      -0.365103\n",
            "L2_coal_cspt_yoy    -0.365869\n",
            "L2_oil_cspt_yoy      0.713775\n",
            "Name: fubon_npl, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "#%% 建立一阶VECM模型，代入模型预测Y\n",
        "X = data.iloc[:,1:data.columns.size]\n",
        "Y = np.log(data['fubon_npl']/(1-data['fubon_npl']))\n",
        "for i in range(1,3):\n",
        "    X[['L%d_' %(i) + j for j in X_dif.columns]] = np.array(X[X_dif.columns].shift(i))\n",
        "data_wlag = pd.merge(Y,X,how='left',left_index=True,right_index=True)\n",
        "corr = data_wlag.corr('spearman')['fubon_npl']\n",
        "print(corr)\n",
        "# 当期及滞后期经济变量符号均无问题"
      ],
      "id": "xHvz7WQ6Rjul"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8N34M20Rjul"
      },
      "source": [
        "### 7.2 遍历所有组合，筛选能通过测试的组合"
      ],
      "id": "D8N34M20Rjul"
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "Ukg76EnjRjul"
      },
      "outputs": [],
      "source": [
        "# 生成各变量经济变量符号\n",
        "global econ_sign \n",
        "econ_sign = pd.DataFrame(data=np.sign(np.array(corr[1:N+1])),index=X_dif.columns)"
      ],
      "id": "Ukg76EnjRjul"
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "qeSMz7RfRjum"
      },
      "outputs": [],
      "source": [
        "# 设定各测试阈值；注：此处可修改各测试阈值\n",
        "lag = 2 ###注：此处可修改滞后期数\n",
        "paranum = 3 ###注：此处可修改遍历模型入模指标数\n",
        "#sig_cutoff = 0.5 ###注：此处可修改单变量显著性阈值（各指标和不良率之间相关系数绝对值）\n",
        "#corr_cutoff = 0.5 ###注：此处可修改相关性筛选阈值（各指标两两智荐相关系数绝对值）\n",
        "pcutoff = 0.1 ###注：此处可修改长期均衡模型系数p值阈值\n",
        "R2percentile = 0 ### 注：此处可修改R2阈值，代表分位数（0代表不根据R2筛掉模型）\n",
        "VIFcutoff = 10 ## 注：此处可修改VIF共线性测试阈值\n",
        "coint_lag_max = 2 ##注：此处可修改协整测试max lagged-difference in the model\n",
        "coint_cutoff_map = {0.1:0,0.05:1,0.01:2}\n",
        "coint_cutoff = 0.1 ##注：此处可修改协整Johansen测试的p-value的阈值 90%，95%，99%，0.1对应90%"
      ],
      "id": "qeSMz7RfRjum"
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "3_MuaG59Rjun",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "713bfe19-8869-4d80-8c87-5a3a3d90edfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2925\n",
            "2268\n"
          ]
        }
      ],
      "source": [
        "# 遍历所有组合\n",
        "sublst = X.columns.tolist()\n",
        "sub_comb = []\n",
        "sub_comb.extend(list(itertools.combinations(sublst,paranum)))\n",
        "# 从上一步sub_comb中去掉包括指标和其自身滞后期的指标组合\n",
        "sub_df = pd.DataFrame(index=sub_comb,columns=['comb','no'])\n",
        "print (len(sub_df))\n",
        "sub_df['del_lag1'] = sub_df.index\n",
        "def del_lag(tuples):\n",
        "    lst = []\n",
        "    for i in tuples:\n",
        "        if i[0] == u'L':\n",
        "            i_new = i[3:]\n",
        "        else:\n",
        "            i_new = i\n",
        "        lst.append(i_new)\n",
        "        \n",
        "    tuples_new = tuple(lst)\n",
        "    set_new = set(tuples_new)\n",
        "    return set_new\n",
        "sub_df['del_lag2'] = sub_df[['del_lag1']].applymap(del_lag)\n",
        "sub_df['del_lag3'] = sub_df[['del_lag2']].applymap(len)\n",
        "sub_df = sub_df[(sub_df['del_lag3']>=paranum)]\n",
        "sub_df.drop(['del_lag2','del_lag3'],axis=1,inplace=True)\n",
        "print (len(sub_df))"
      ],
      "id": "3_MuaG59Rjun"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiGqZXxiRjun"
      },
      "source": [
        "### 7.3 回归"
      ],
      "id": "EiGqZXxiRjun"
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "debSm1FMRjuo"
      },
      "outputs": [],
      "source": [
        "# 计算sub_df中模型的回归系数,p统计量，R^2，VIF系数\n",
        "varlst = []\n",
        "for i in range(1,paranum+1):\n",
        "    varlst.append(u'变量' + str(i))\n",
        "betalst = [u'Intercept']\n",
        "for i in range(1,paranum+1):\n",
        "    betalst.append(u'Beta' + str(i))\n",
        "plst = [u'p0']\n",
        "for i in range(1,paranum+1):\n",
        "    plst.append(u'p' + str(i))\n",
        "regresults_colst = []\n",
        "regresults_colst.extend(varlst)\n",
        "regresults_colst.extend(betalst)\n",
        "regresults_colst.extend(plst)\n",
        "regresults_colst.append(u'R2')\n",
        "viflst = []\n",
        "for i in range(1,paranum+1):\n",
        "    viflst.append(u'vif_变量' + str(i))\n",
        "regresults_colst.extend(viflst)\n",
        "\n",
        "regresults = pd.DataFrame(columns=regresults_colst)\n",
        "\n",
        "y = Y"
      ],
      "id": "debSm1FMRjuo"
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "hVN1AZMqRjuo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fde1a21-68c0-49dd-d7f2-4afc9fda6555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 out of 2268\n",
            "2 out of 2268\n",
            "3 out of 2268\n",
            "4 out of 2268\n",
            "5 out of 2268\n",
            "6 out of 2268\n",
            "7 out of 2268\n",
            "8 out of 2268\n",
            "9 out of 2268\n",
            "10 out of 2268\n",
            "11 out of 2268\n",
            "12 out of 2268\n",
            "13 out of 2268\n",
            "14 out of 2268\n",
            "15 out of 2268\n",
            "16 out of 2268\n",
            "17 out of 2268\n",
            "18 out of 2268\n",
            "19 out of 2268\n",
            "20 out of 2268\n",
            "21 out of 2268\n",
            "22 out of 2268\n",
            "23 out of 2268\n",
            "24 out of 2268\n",
            "25 out of 2268\n",
            "26 out of 2268\n",
            "27 out of 2268\n",
            "28 out of 2268\n",
            "29 out of 2268\n",
            "30 out of 2268\n",
            "31 out of 2268\n",
            "32 out of 2268\n",
            "33 out of 2268\n",
            "34 out of 2268\n",
            "35 out of 2268\n",
            "36 out of 2268\n",
            "37 out of 2268\n",
            "38 out of 2268\n",
            "39 out of 2268\n",
            "40 out of 2268\n",
            "41 out of 2268\n",
            "42 out of 2268\n",
            "43 out of 2268\n",
            "44 out of 2268\n",
            "45 out of 2268\n",
            "46 out of 2268\n",
            "47 out of 2268\n",
            "48 out of 2268\n",
            "49 out of 2268\n",
            "50 out of 2268\n",
            "51 out of 2268\n",
            "52 out of 2268\n",
            "53 out of 2268\n",
            "54 out of 2268\n",
            "55 out of 2268\n",
            "56 out of 2268\n",
            "57 out of 2268\n",
            "58 out of 2268\n",
            "59 out of 2268\n",
            "60 out of 2268\n",
            "61 out of 2268\n",
            "62 out of 2268\n",
            "63 out of 2268\n",
            "64 out of 2268\n",
            "65 out of 2268\n",
            "66 out of 2268\n",
            "67 out of 2268\n",
            "68 out of 2268\n",
            "69 out of 2268\n",
            "70 out of 2268\n",
            "71 out of 2268\n",
            "72 out of 2268\n",
            "73 out of 2268\n",
            "74 out of 2268\n",
            "75 out of 2268\n",
            "76 out of 2268\n",
            "77 out of 2268\n",
            "78 out of 2268\n",
            "79 out of 2268\n",
            "80 out of 2268\n",
            "81 out of 2268\n",
            "82 out of 2268\n",
            "83 out of 2268\n",
            "84 out of 2268\n",
            "85 out of 2268\n",
            "86 out of 2268\n",
            "87 out of 2268\n",
            "88 out of 2268\n",
            "89 out of 2268\n",
            "90 out of 2268\n",
            "91 out of 2268\n",
            "92 out of 2268\n",
            "93 out of 2268\n",
            "94 out of 2268\n",
            "95 out of 2268\n",
            "96 out of 2268\n",
            "97 out of 2268\n",
            "98 out of 2268\n",
            "99 out of 2268\n",
            "100 out of 2268\n",
            "101 out of 2268\n",
            "102 out of 2268\n",
            "103 out of 2268\n",
            "104 out of 2268\n",
            "105 out of 2268\n",
            "106 out of 2268\n",
            "107 out of 2268\n",
            "108 out of 2268\n",
            "109 out of 2268\n",
            "110 out of 2268\n",
            "111 out of 2268\n",
            "112 out of 2268\n",
            "113 out of 2268\n",
            "114 out of 2268\n",
            "115 out of 2268\n",
            "116 out of 2268\n",
            "117 out of 2268\n",
            "118 out of 2268\n",
            "119 out of 2268\n",
            "120 out of 2268\n",
            "121 out of 2268\n",
            "122 out of 2268\n",
            "123 out of 2268\n",
            "124 out of 2268\n",
            "125 out of 2268\n",
            "126 out of 2268\n",
            "127 out of 2268\n",
            "128 out of 2268\n",
            "129 out of 2268\n",
            "130 out of 2268\n",
            "131 out of 2268\n",
            "132 out of 2268\n",
            "133 out of 2268\n",
            "134 out of 2268\n",
            "135 out of 2268\n",
            "136 out of 2268\n",
            "137 out of 2268\n",
            "138 out of 2268\n",
            "139 out of 2268\n",
            "140 out of 2268\n",
            "141 out of 2268\n",
            "142 out of 2268\n",
            "143 out of 2268\n",
            "144 out of 2268\n",
            "145 out of 2268\n",
            "146 out of 2268\n",
            "147 out of 2268\n",
            "148 out of 2268\n",
            "149 out of 2268\n",
            "150 out of 2268\n",
            "151 out of 2268\n",
            "152 out of 2268\n",
            "153 out of 2268\n",
            "154 out of 2268\n",
            "155 out of 2268\n",
            "156 out of 2268\n",
            "157 out of 2268\n",
            "158 out of 2268\n",
            "159 out of 2268\n",
            "160 out of 2268\n",
            "161 out of 2268\n",
            "162 out of 2268\n",
            "163 out of 2268\n",
            "164 out of 2268\n",
            "165 out of 2268\n",
            "166 out of 2268\n",
            "167 out of 2268\n",
            "168 out of 2268\n",
            "169 out of 2268\n",
            "170 out of 2268\n",
            "171 out of 2268\n",
            "172 out of 2268\n",
            "173 out of 2268\n",
            "174 out of 2268\n",
            "175 out of 2268\n",
            "176 out of 2268\n",
            "177 out of 2268\n",
            "178 out of 2268\n",
            "179 out of 2268\n",
            "180 out of 2268\n",
            "181 out of 2268\n",
            "182 out of 2268\n",
            "183 out of 2268\n",
            "184 out of 2268\n",
            "185 out of 2268\n",
            "186 out of 2268\n",
            "187 out of 2268\n",
            "188 out of 2268\n",
            "189 out of 2268\n",
            "190 out of 2268\n",
            "191 out of 2268\n",
            "192 out of 2268\n",
            "193 out of 2268\n",
            "194 out of 2268\n",
            "195 out of 2268\n",
            "196 out of 2268\n",
            "197 out of 2268\n",
            "198 out of 2268\n",
            "199 out of 2268\n",
            "200 out of 2268\n",
            "201 out of 2268\n",
            "202 out of 2268\n",
            "203 out of 2268\n",
            "204 out of 2268\n",
            "205 out of 2268\n",
            "206 out of 2268\n",
            "207 out of 2268\n",
            "208 out of 2268\n",
            "209 out of 2268\n",
            "210 out of 2268\n",
            "211 out of 2268\n",
            "212 out of 2268\n",
            "213 out of 2268\n",
            "214 out of 2268\n",
            "215 out of 2268\n",
            "216 out of 2268\n",
            "217 out of 2268\n",
            "218 out of 2268\n",
            "219 out of 2268\n",
            "220 out of 2268\n",
            "221 out of 2268\n",
            "222 out of 2268\n",
            "223 out of 2268\n",
            "224 out of 2268\n",
            "225 out of 2268\n",
            "226 out of 2268\n",
            "227 out of 2268\n",
            "228 out of 2268\n",
            "229 out of 2268\n",
            "230 out of 2268\n",
            "231 out of 2268\n",
            "232 out of 2268\n",
            "233 out of 2268\n",
            "234 out of 2268\n",
            "235 out of 2268\n",
            "236 out of 2268\n",
            "237 out of 2268\n",
            "238 out of 2268\n",
            "239 out of 2268\n",
            "240 out of 2268\n",
            "241 out of 2268\n",
            "242 out of 2268\n",
            "243 out of 2268\n",
            "244 out of 2268\n",
            "245 out of 2268\n",
            "246 out of 2268\n",
            "247 out of 2268\n",
            "248 out of 2268\n",
            "249 out of 2268\n",
            "250 out of 2268\n",
            "251 out of 2268\n",
            "252 out of 2268\n",
            "253 out of 2268\n",
            "254 out of 2268\n",
            "255 out of 2268\n",
            "256 out of 2268\n",
            "257 out of 2268\n",
            "258 out of 2268\n",
            "259 out of 2268\n",
            "260 out of 2268\n",
            "261 out of 2268\n",
            "262 out of 2268\n",
            "263 out of 2268\n",
            "264 out of 2268\n",
            "265 out of 2268\n",
            "266 out of 2268\n",
            "267 out of 2268\n",
            "268 out of 2268\n",
            "269 out of 2268\n",
            "270 out of 2268\n",
            "271 out of 2268\n",
            "272 out of 2268\n",
            "273 out of 2268\n",
            "274 out of 2268\n",
            "275 out of 2268\n",
            "276 out of 2268\n",
            "277 out of 2268\n",
            "278 out of 2268\n",
            "279 out of 2268\n",
            "280 out of 2268\n",
            "281 out of 2268\n",
            "282 out of 2268\n",
            "283 out of 2268\n",
            "284 out of 2268\n",
            "285 out of 2268\n",
            "286 out of 2268\n",
            "287 out of 2268\n",
            "288 out of 2268\n",
            "289 out of 2268\n",
            "290 out of 2268\n",
            "291 out of 2268\n",
            "292 out of 2268\n",
            "293 out of 2268\n",
            "294 out of 2268\n",
            "295 out of 2268\n",
            "296 out of 2268\n",
            "297 out of 2268\n",
            "298 out of 2268\n",
            "299 out of 2268\n",
            "300 out of 2268\n",
            "301 out of 2268\n",
            "302 out of 2268\n",
            "303 out of 2268\n",
            "304 out of 2268\n",
            "305 out of 2268\n",
            "306 out of 2268\n",
            "307 out of 2268\n",
            "308 out of 2268\n",
            "309 out of 2268\n",
            "310 out of 2268\n",
            "311 out of 2268\n",
            "312 out of 2268\n",
            "313 out of 2268\n",
            "314 out of 2268\n",
            "315 out of 2268\n",
            "316 out of 2268\n",
            "317 out of 2268\n",
            "318 out of 2268\n",
            "319 out of 2268\n",
            "320 out of 2268\n",
            "321 out of 2268\n",
            "322 out of 2268\n",
            "323 out of 2268\n",
            "324 out of 2268\n",
            "325 out of 2268\n",
            "326 out of 2268\n",
            "327 out of 2268\n",
            "328 out of 2268\n",
            "329 out of 2268\n",
            "330 out of 2268\n",
            "331 out of 2268\n",
            "332 out of 2268\n",
            "333 out of 2268\n",
            "334 out of 2268\n",
            "335 out of 2268\n",
            "336 out of 2268\n",
            "337 out of 2268\n",
            "338 out of 2268\n",
            "339 out of 2268\n",
            "340 out of 2268\n",
            "341 out of 2268\n",
            "342 out of 2268\n",
            "343 out of 2268\n",
            "344 out of 2268\n",
            "345 out of 2268\n",
            "346 out of 2268\n",
            "347 out of 2268\n",
            "348 out of 2268\n",
            "349 out of 2268\n",
            "350 out of 2268\n",
            "351 out of 2268\n",
            "352 out of 2268\n",
            "353 out of 2268\n",
            "354 out of 2268\n",
            "355 out of 2268\n",
            "356 out of 2268\n",
            "357 out of 2268\n",
            "358 out of 2268\n",
            "359 out of 2268\n",
            "360 out of 2268\n",
            "361 out of 2268\n",
            "362 out of 2268\n",
            "363 out of 2268\n",
            "364 out of 2268\n",
            "365 out of 2268\n",
            "366 out of 2268\n",
            "367 out of 2268\n",
            "368 out of 2268\n",
            "369 out of 2268\n",
            "370 out of 2268\n",
            "371 out of 2268\n",
            "372 out of 2268\n",
            "373 out of 2268\n",
            "374 out of 2268\n",
            "375 out of 2268\n",
            "376 out of 2268\n",
            "377 out of 2268\n",
            "378 out of 2268\n",
            "379 out of 2268\n",
            "380 out of 2268\n",
            "381 out of 2268\n",
            "382 out of 2268\n",
            "383 out of 2268\n",
            "384 out of 2268\n",
            "385 out of 2268\n",
            "386 out of 2268\n",
            "387 out of 2268\n",
            "388 out of 2268\n",
            "389 out of 2268\n",
            "390 out of 2268\n",
            "391 out of 2268\n",
            "392 out of 2268\n",
            "393 out of 2268\n",
            "394 out of 2268\n",
            "395 out of 2268\n",
            "396 out of 2268\n",
            "397 out of 2268\n",
            "398 out of 2268\n",
            "399 out of 2268\n",
            "400 out of 2268\n",
            "401 out of 2268\n",
            "402 out of 2268\n",
            "403 out of 2268\n",
            "404 out of 2268\n",
            "405 out of 2268\n",
            "406 out of 2268\n",
            "407 out of 2268\n",
            "408 out of 2268\n",
            "409 out of 2268\n",
            "410 out of 2268\n",
            "411 out of 2268\n",
            "412 out of 2268\n",
            "413 out of 2268\n",
            "414 out of 2268\n",
            "415 out of 2268\n",
            "416 out of 2268\n",
            "417 out of 2268\n",
            "418 out of 2268\n",
            "419 out of 2268\n",
            "420 out of 2268\n",
            "421 out of 2268\n",
            "422 out of 2268\n",
            "423 out of 2268\n",
            "424 out of 2268\n",
            "425 out of 2268\n",
            "426 out of 2268\n",
            "427 out of 2268\n",
            "428 out of 2268\n",
            "429 out of 2268\n",
            "430 out of 2268\n",
            "431 out of 2268\n",
            "432 out of 2268\n",
            "433 out of 2268\n",
            "434 out of 2268\n",
            "435 out of 2268\n",
            "436 out of 2268\n",
            "437 out of 2268\n",
            "438 out of 2268\n",
            "439 out of 2268\n",
            "440 out of 2268\n",
            "441 out of 2268\n",
            "442 out of 2268\n",
            "443 out of 2268\n",
            "444 out of 2268\n",
            "445 out of 2268\n",
            "446 out of 2268\n",
            "447 out of 2268\n",
            "448 out of 2268\n",
            "449 out of 2268\n",
            "450 out of 2268\n",
            "451 out of 2268\n",
            "452 out of 2268\n",
            "453 out of 2268\n",
            "454 out of 2268\n",
            "455 out of 2268\n",
            "456 out of 2268\n",
            "457 out of 2268\n",
            "458 out of 2268\n",
            "459 out of 2268\n",
            "460 out of 2268\n",
            "461 out of 2268\n",
            "462 out of 2268\n",
            "463 out of 2268\n",
            "464 out of 2268\n",
            "465 out of 2268\n",
            "466 out of 2268\n",
            "467 out of 2268\n",
            "468 out of 2268\n",
            "469 out of 2268\n",
            "470 out of 2268\n",
            "471 out of 2268\n",
            "472 out of 2268\n",
            "473 out of 2268\n",
            "474 out of 2268\n",
            "475 out of 2268\n",
            "476 out of 2268\n",
            "477 out of 2268\n",
            "478 out of 2268\n",
            "479 out of 2268\n",
            "480 out of 2268\n",
            "481 out of 2268\n",
            "482 out of 2268\n",
            "483 out of 2268\n",
            "484 out of 2268\n",
            "485 out of 2268\n",
            "486 out of 2268\n",
            "487 out of 2268\n",
            "488 out of 2268\n",
            "489 out of 2268\n",
            "490 out of 2268\n",
            "491 out of 2268\n",
            "492 out of 2268\n",
            "493 out of 2268\n",
            "494 out of 2268\n",
            "495 out of 2268\n",
            "496 out of 2268\n",
            "497 out of 2268\n",
            "498 out of 2268\n",
            "499 out of 2268\n",
            "500 out of 2268\n",
            "501 out of 2268\n",
            "502 out of 2268\n",
            "503 out of 2268\n",
            "504 out of 2268\n",
            "505 out of 2268\n",
            "506 out of 2268\n",
            "507 out of 2268\n",
            "508 out of 2268\n",
            "509 out of 2268\n",
            "510 out of 2268\n",
            "511 out of 2268\n",
            "512 out of 2268\n",
            "513 out of 2268\n",
            "514 out of 2268\n",
            "515 out of 2268\n",
            "516 out of 2268\n",
            "517 out of 2268\n",
            "518 out of 2268\n",
            "519 out of 2268\n",
            "520 out of 2268\n",
            "521 out of 2268\n",
            "522 out of 2268\n",
            "523 out of 2268\n",
            "524 out of 2268\n",
            "525 out of 2268\n",
            "526 out of 2268\n",
            "527 out of 2268\n",
            "528 out of 2268\n",
            "529 out of 2268\n",
            "530 out of 2268\n",
            "531 out of 2268\n",
            "532 out of 2268\n",
            "533 out of 2268\n",
            "534 out of 2268\n",
            "535 out of 2268\n",
            "536 out of 2268\n",
            "537 out of 2268\n",
            "538 out of 2268\n",
            "539 out of 2268\n",
            "540 out of 2268\n",
            "541 out of 2268\n",
            "542 out of 2268\n",
            "543 out of 2268\n",
            "544 out of 2268\n",
            "545 out of 2268\n",
            "546 out of 2268\n",
            "547 out of 2268\n",
            "548 out of 2268\n",
            "549 out of 2268\n",
            "550 out of 2268\n",
            "551 out of 2268\n",
            "552 out of 2268\n",
            "553 out of 2268\n",
            "554 out of 2268\n",
            "555 out of 2268\n",
            "556 out of 2268\n",
            "557 out of 2268\n",
            "558 out of 2268\n",
            "559 out of 2268\n",
            "560 out of 2268\n",
            "561 out of 2268\n",
            "562 out of 2268\n",
            "563 out of 2268\n",
            "564 out of 2268\n",
            "565 out of 2268\n",
            "566 out of 2268\n",
            "567 out of 2268\n",
            "568 out of 2268\n",
            "569 out of 2268\n",
            "570 out of 2268\n",
            "571 out of 2268\n",
            "572 out of 2268\n",
            "573 out of 2268\n",
            "574 out of 2268\n",
            "575 out of 2268\n",
            "576 out of 2268\n",
            "577 out of 2268\n",
            "578 out of 2268\n",
            "579 out of 2268\n",
            "580 out of 2268\n",
            "581 out of 2268\n",
            "582 out of 2268\n",
            "583 out of 2268\n",
            "584 out of 2268\n",
            "585 out of 2268\n",
            "586 out of 2268\n",
            "587 out of 2268\n",
            "588 out of 2268\n",
            "589 out of 2268\n",
            "590 out of 2268\n",
            "591 out of 2268\n",
            "592 out of 2268\n",
            "593 out of 2268\n",
            "594 out of 2268\n",
            "595 out of 2268\n",
            "596 out of 2268\n",
            "597 out of 2268\n",
            "598 out of 2268\n",
            "599 out of 2268\n",
            "600 out of 2268\n",
            "601 out of 2268\n",
            "602 out of 2268\n",
            "603 out of 2268\n",
            "604 out of 2268\n",
            "605 out of 2268\n",
            "606 out of 2268\n",
            "607 out of 2268\n",
            "608 out of 2268\n",
            "609 out of 2268\n",
            "610 out of 2268\n",
            "611 out of 2268\n",
            "612 out of 2268\n",
            "613 out of 2268\n",
            "614 out of 2268\n",
            "615 out of 2268\n",
            "616 out of 2268\n",
            "617 out of 2268\n",
            "618 out of 2268\n",
            "619 out of 2268\n",
            "620 out of 2268\n",
            "621 out of 2268\n",
            "622 out of 2268\n",
            "623 out of 2268\n",
            "624 out of 2268\n",
            "625 out of 2268\n",
            "626 out of 2268\n",
            "627 out of 2268\n",
            "628 out of 2268\n",
            "629 out of 2268\n",
            "630 out of 2268\n",
            "631 out of 2268\n",
            "632 out of 2268\n",
            "633 out of 2268\n",
            "634 out of 2268\n",
            "635 out of 2268\n",
            "636 out of 2268\n",
            "637 out of 2268\n",
            "638 out of 2268\n",
            "639 out of 2268\n",
            "640 out of 2268\n",
            "641 out of 2268\n",
            "642 out of 2268\n",
            "643 out of 2268\n",
            "644 out of 2268\n",
            "645 out of 2268\n",
            "646 out of 2268\n",
            "647 out of 2268\n",
            "648 out of 2268\n",
            "649 out of 2268\n",
            "650 out of 2268\n",
            "651 out of 2268\n",
            "652 out of 2268\n",
            "653 out of 2268\n",
            "654 out of 2268\n",
            "655 out of 2268\n",
            "656 out of 2268\n",
            "657 out of 2268\n",
            "658 out of 2268\n",
            "659 out of 2268\n",
            "660 out of 2268\n",
            "661 out of 2268\n",
            "662 out of 2268\n",
            "663 out of 2268\n",
            "664 out of 2268\n",
            "665 out of 2268\n",
            "666 out of 2268\n",
            "667 out of 2268\n",
            "668 out of 2268\n",
            "669 out of 2268\n",
            "670 out of 2268\n",
            "671 out of 2268\n",
            "672 out of 2268\n",
            "673 out of 2268\n",
            "674 out of 2268\n",
            "675 out of 2268\n",
            "676 out of 2268\n",
            "677 out of 2268\n",
            "678 out of 2268\n",
            "679 out of 2268\n",
            "680 out of 2268\n",
            "681 out of 2268\n",
            "682 out of 2268\n",
            "683 out of 2268\n",
            "684 out of 2268\n",
            "685 out of 2268\n",
            "686 out of 2268\n",
            "687 out of 2268\n",
            "688 out of 2268\n",
            "689 out of 2268\n",
            "690 out of 2268\n",
            "691 out of 2268\n",
            "692 out of 2268\n",
            "693 out of 2268\n",
            "694 out of 2268\n",
            "695 out of 2268\n",
            "696 out of 2268\n",
            "697 out of 2268\n",
            "698 out of 2268\n",
            "699 out of 2268\n",
            "700 out of 2268\n",
            "701 out of 2268\n",
            "702 out of 2268\n",
            "703 out of 2268\n",
            "704 out of 2268\n",
            "705 out of 2268\n",
            "706 out of 2268\n",
            "707 out of 2268\n",
            "708 out of 2268\n",
            "709 out of 2268\n",
            "710 out of 2268\n",
            "711 out of 2268\n",
            "712 out of 2268\n",
            "713 out of 2268\n",
            "714 out of 2268\n",
            "715 out of 2268\n",
            "716 out of 2268\n",
            "717 out of 2268\n",
            "718 out of 2268\n",
            "719 out of 2268\n",
            "720 out of 2268\n",
            "721 out of 2268\n",
            "722 out of 2268\n",
            "723 out of 2268\n",
            "724 out of 2268\n",
            "725 out of 2268\n",
            "726 out of 2268\n",
            "727 out of 2268\n",
            "728 out of 2268\n",
            "729 out of 2268\n",
            "730 out of 2268\n",
            "731 out of 2268\n",
            "732 out of 2268\n",
            "733 out of 2268\n",
            "734 out of 2268\n",
            "735 out of 2268\n",
            "736 out of 2268\n",
            "737 out of 2268\n",
            "738 out of 2268\n",
            "739 out of 2268\n",
            "740 out of 2268\n",
            "741 out of 2268\n",
            "742 out of 2268\n",
            "743 out of 2268\n",
            "744 out of 2268\n",
            "745 out of 2268\n",
            "746 out of 2268\n",
            "747 out of 2268\n",
            "748 out of 2268\n",
            "749 out of 2268\n",
            "750 out of 2268\n",
            "751 out of 2268\n",
            "752 out of 2268\n",
            "753 out of 2268\n",
            "754 out of 2268\n",
            "755 out of 2268\n",
            "756 out of 2268\n",
            "757 out of 2268\n",
            "758 out of 2268\n",
            "759 out of 2268\n",
            "760 out of 2268\n",
            "761 out of 2268\n",
            "762 out of 2268\n",
            "763 out of 2268\n",
            "764 out of 2268\n",
            "765 out of 2268\n",
            "766 out of 2268\n",
            "767 out of 2268\n",
            "768 out of 2268\n",
            "769 out of 2268\n",
            "770 out of 2268\n",
            "771 out of 2268\n",
            "772 out of 2268\n",
            "773 out of 2268\n",
            "774 out of 2268\n",
            "775 out of 2268\n",
            "776 out of 2268\n",
            "777 out of 2268\n",
            "778 out of 2268\n",
            "779 out of 2268\n",
            "780 out of 2268\n",
            "781 out of 2268\n",
            "782 out of 2268\n",
            "783 out of 2268\n",
            "784 out of 2268\n",
            "785 out of 2268\n",
            "786 out of 2268\n",
            "787 out of 2268\n",
            "788 out of 2268\n",
            "789 out of 2268\n",
            "790 out of 2268\n",
            "791 out of 2268\n",
            "792 out of 2268\n",
            "793 out of 2268\n",
            "794 out of 2268\n",
            "795 out of 2268\n",
            "796 out of 2268\n",
            "797 out of 2268\n",
            "798 out of 2268\n",
            "799 out of 2268\n",
            "800 out of 2268\n",
            "801 out of 2268\n",
            "802 out of 2268\n",
            "803 out of 2268\n",
            "804 out of 2268\n",
            "805 out of 2268\n",
            "806 out of 2268\n",
            "807 out of 2268\n",
            "808 out of 2268\n",
            "809 out of 2268\n",
            "810 out of 2268\n",
            "811 out of 2268\n",
            "812 out of 2268\n",
            "813 out of 2268\n",
            "814 out of 2268\n",
            "815 out of 2268\n",
            "816 out of 2268\n",
            "817 out of 2268\n",
            "818 out of 2268\n",
            "819 out of 2268\n",
            "820 out of 2268\n",
            "821 out of 2268\n",
            "822 out of 2268\n",
            "823 out of 2268\n",
            "824 out of 2268\n",
            "825 out of 2268\n",
            "826 out of 2268\n",
            "827 out of 2268\n",
            "828 out of 2268\n",
            "829 out of 2268\n",
            "830 out of 2268\n",
            "831 out of 2268\n",
            "832 out of 2268\n",
            "833 out of 2268\n",
            "834 out of 2268\n",
            "835 out of 2268\n",
            "836 out of 2268\n",
            "837 out of 2268\n",
            "838 out of 2268\n",
            "839 out of 2268\n",
            "840 out of 2268\n",
            "841 out of 2268\n",
            "842 out of 2268\n",
            "843 out of 2268\n",
            "844 out of 2268\n",
            "845 out of 2268\n",
            "846 out of 2268\n",
            "847 out of 2268\n",
            "848 out of 2268\n",
            "849 out of 2268\n",
            "850 out of 2268\n",
            "851 out of 2268\n",
            "852 out of 2268\n",
            "853 out of 2268\n",
            "854 out of 2268\n",
            "855 out of 2268\n",
            "856 out of 2268\n",
            "857 out of 2268\n",
            "858 out of 2268\n",
            "859 out of 2268\n",
            "860 out of 2268\n",
            "861 out of 2268\n",
            "862 out of 2268\n",
            "863 out of 2268\n",
            "864 out of 2268\n",
            "865 out of 2268\n",
            "866 out of 2268\n",
            "867 out of 2268\n",
            "868 out of 2268\n",
            "869 out of 2268\n",
            "870 out of 2268\n",
            "871 out of 2268\n",
            "872 out of 2268\n",
            "873 out of 2268\n",
            "874 out of 2268\n",
            "875 out of 2268\n",
            "876 out of 2268\n",
            "877 out of 2268\n",
            "878 out of 2268\n",
            "879 out of 2268\n",
            "880 out of 2268\n",
            "881 out of 2268\n",
            "882 out of 2268\n",
            "883 out of 2268\n",
            "884 out of 2268\n",
            "885 out of 2268\n",
            "886 out of 2268\n",
            "887 out of 2268\n",
            "888 out of 2268\n",
            "889 out of 2268\n",
            "890 out of 2268\n",
            "891 out of 2268\n",
            "892 out of 2268\n",
            "893 out of 2268\n",
            "894 out of 2268\n",
            "895 out of 2268\n",
            "896 out of 2268\n",
            "897 out of 2268\n",
            "898 out of 2268\n",
            "899 out of 2268\n",
            "900 out of 2268\n",
            "901 out of 2268\n",
            "902 out of 2268\n",
            "903 out of 2268\n",
            "904 out of 2268\n",
            "905 out of 2268\n",
            "906 out of 2268\n",
            "907 out of 2268\n",
            "908 out of 2268\n",
            "909 out of 2268\n",
            "910 out of 2268\n",
            "911 out of 2268\n",
            "912 out of 2268\n",
            "913 out of 2268\n",
            "914 out of 2268\n",
            "915 out of 2268\n",
            "916 out of 2268\n",
            "917 out of 2268\n",
            "918 out of 2268\n",
            "919 out of 2268\n",
            "920 out of 2268\n",
            "921 out of 2268\n",
            "922 out of 2268\n",
            "923 out of 2268\n",
            "924 out of 2268\n",
            "925 out of 2268\n",
            "926 out of 2268\n",
            "927 out of 2268\n",
            "928 out of 2268\n",
            "929 out of 2268\n",
            "930 out of 2268\n",
            "931 out of 2268\n",
            "932 out of 2268\n",
            "933 out of 2268\n",
            "934 out of 2268\n",
            "935 out of 2268\n",
            "936 out of 2268\n",
            "937 out of 2268\n",
            "938 out of 2268\n",
            "939 out of 2268\n",
            "940 out of 2268\n",
            "941 out of 2268\n",
            "942 out of 2268\n",
            "943 out of 2268\n",
            "944 out of 2268\n",
            "945 out of 2268\n",
            "946 out of 2268\n",
            "947 out of 2268\n",
            "948 out of 2268\n",
            "949 out of 2268\n",
            "950 out of 2268\n",
            "951 out of 2268\n",
            "952 out of 2268\n",
            "953 out of 2268\n",
            "954 out of 2268\n",
            "955 out of 2268\n",
            "956 out of 2268\n",
            "957 out of 2268\n",
            "958 out of 2268\n",
            "959 out of 2268\n",
            "960 out of 2268\n",
            "961 out of 2268\n",
            "962 out of 2268\n",
            "963 out of 2268\n",
            "964 out of 2268\n",
            "965 out of 2268\n",
            "966 out of 2268\n",
            "967 out of 2268\n",
            "968 out of 2268\n",
            "969 out of 2268\n",
            "970 out of 2268\n",
            "971 out of 2268\n",
            "972 out of 2268\n",
            "973 out of 2268\n",
            "974 out of 2268\n",
            "975 out of 2268\n",
            "976 out of 2268\n",
            "977 out of 2268\n",
            "978 out of 2268\n",
            "979 out of 2268\n",
            "980 out of 2268\n",
            "981 out of 2268\n",
            "982 out of 2268\n",
            "983 out of 2268\n",
            "984 out of 2268\n",
            "985 out of 2268\n",
            "986 out of 2268\n",
            "987 out of 2268\n",
            "988 out of 2268\n",
            "989 out of 2268\n",
            "990 out of 2268\n",
            "991 out of 2268\n",
            "992 out of 2268\n",
            "993 out of 2268\n",
            "994 out of 2268\n",
            "995 out of 2268\n",
            "996 out of 2268\n",
            "997 out of 2268\n",
            "998 out of 2268\n",
            "999 out of 2268\n",
            "1000 out of 2268\n",
            "1001 out of 2268\n",
            "1002 out of 2268\n",
            "1003 out of 2268\n",
            "1004 out of 2268\n",
            "1005 out of 2268\n",
            "1006 out of 2268\n",
            "1007 out of 2268\n",
            "1008 out of 2268\n",
            "1009 out of 2268\n",
            "1010 out of 2268\n",
            "1011 out of 2268\n",
            "1012 out of 2268\n",
            "1013 out of 2268\n",
            "1014 out of 2268\n",
            "1015 out of 2268\n",
            "1016 out of 2268\n",
            "1017 out of 2268\n",
            "1018 out of 2268\n",
            "1019 out of 2268\n",
            "1020 out of 2268\n",
            "1021 out of 2268\n",
            "1022 out of 2268\n",
            "1023 out of 2268\n",
            "1024 out of 2268\n",
            "1025 out of 2268\n",
            "1026 out of 2268\n",
            "1027 out of 2268\n",
            "1028 out of 2268\n",
            "1029 out of 2268\n",
            "1030 out of 2268\n",
            "1031 out of 2268\n",
            "1032 out of 2268\n",
            "1033 out of 2268\n",
            "1034 out of 2268\n",
            "1035 out of 2268\n",
            "1036 out of 2268\n",
            "1037 out of 2268\n",
            "1038 out of 2268\n",
            "1039 out of 2268\n",
            "1040 out of 2268\n",
            "1041 out of 2268\n",
            "1042 out of 2268\n",
            "1043 out of 2268\n",
            "1044 out of 2268\n",
            "1045 out of 2268\n",
            "1046 out of 2268\n",
            "1047 out of 2268\n",
            "1048 out of 2268\n",
            "1049 out of 2268\n",
            "1050 out of 2268\n",
            "1051 out of 2268\n",
            "1052 out of 2268\n",
            "1053 out of 2268\n",
            "1054 out of 2268\n",
            "1055 out of 2268\n",
            "1056 out of 2268\n",
            "1057 out of 2268\n",
            "1058 out of 2268\n",
            "1059 out of 2268\n",
            "1060 out of 2268\n",
            "1061 out of 2268\n",
            "1062 out of 2268\n",
            "1063 out of 2268\n",
            "1064 out of 2268\n",
            "1065 out of 2268\n",
            "1066 out of 2268\n",
            "1067 out of 2268\n",
            "1068 out of 2268\n",
            "1069 out of 2268\n",
            "1070 out of 2268\n",
            "1071 out of 2268\n",
            "1072 out of 2268\n",
            "1073 out of 2268\n",
            "1074 out of 2268\n",
            "1075 out of 2268\n",
            "1076 out of 2268\n",
            "1077 out of 2268\n",
            "1078 out of 2268\n",
            "1079 out of 2268\n",
            "1080 out of 2268\n",
            "1081 out of 2268\n",
            "1082 out of 2268\n",
            "1083 out of 2268\n",
            "1084 out of 2268\n",
            "1085 out of 2268\n",
            "1086 out of 2268\n",
            "1087 out of 2268\n",
            "1088 out of 2268\n",
            "1089 out of 2268\n",
            "1090 out of 2268\n",
            "1091 out of 2268\n",
            "1092 out of 2268\n",
            "1093 out of 2268\n",
            "1094 out of 2268\n",
            "1095 out of 2268\n",
            "1096 out of 2268\n",
            "1097 out of 2268\n",
            "1098 out of 2268\n",
            "1099 out of 2268\n",
            "1100 out of 2268\n",
            "1101 out of 2268\n",
            "1102 out of 2268\n",
            "1103 out of 2268\n",
            "1104 out of 2268\n",
            "1105 out of 2268\n",
            "1106 out of 2268\n",
            "1107 out of 2268\n",
            "1108 out of 2268\n",
            "1109 out of 2268\n",
            "1110 out of 2268\n",
            "1111 out of 2268\n",
            "1112 out of 2268\n",
            "1113 out of 2268\n",
            "1114 out of 2268\n",
            "1115 out of 2268\n",
            "1116 out of 2268\n",
            "1117 out of 2268\n",
            "1118 out of 2268\n",
            "1119 out of 2268\n",
            "1120 out of 2268\n",
            "1121 out of 2268\n",
            "1122 out of 2268\n",
            "1123 out of 2268\n",
            "1124 out of 2268\n",
            "1125 out of 2268\n",
            "1126 out of 2268\n",
            "1127 out of 2268\n",
            "1128 out of 2268\n",
            "1129 out of 2268\n",
            "1130 out of 2268\n",
            "1131 out of 2268\n",
            "1132 out of 2268\n",
            "1133 out of 2268\n",
            "1134 out of 2268\n",
            "1135 out of 2268\n",
            "1136 out of 2268\n",
            "1137 out of 2268\n",
            "1138 out of 2268\n",
            "1139 out of 2268\n",
            "1140 out of 2268\n",
            "1141 out of 2268\n",
            "1142 out of 2268\n",
            "1143 out of 2268\n",
            "1144 out of 2268\n",
            "1145 out of 2268\n",
            "1146 out of 2268\n",
            "1147 out of 2268\n",
            "1148 out of 2268\n",
            "1149 out of 2268\n",
            "1150 out of 2268\n",
            "1151 out of 2268\n",
            "1152 out of 2268\n",
            "1153 out of 2268\n",
            "1154 out of 2268\n",
            "1155 out of 2268\n",
            "1156 out of 2268\n",
            "1157 out of 2268\n",
            "1158 out of 2268\n",
            "1159 out of 2268\n",
            "1160 out of 2268\n",
            "1161 out of 2268\n",
            "1162 out of 2268\n",
            "1163 out of 2268\n",
            "1164 out of 2268\n",
            "1165 out of 2268\n",
            "1166 out of 2268\n",
            "1167 out of 2268\n",
            "1168 out of 2268\n",
            "1169 out of 2268\n",
            "1170 out of 2268\n",
            "1171 out of 2268\n",
            "1172 out of 2268\n",
            "1173 out of 2268\n",
            "1174 out of 2268\n",
            "1175 out of 2268\n",
            "1176 out of 2268\n",
            "1177 out of 2268\n",
            "1178 out of 2268\n",
            "1179 out of 2268\n",
            "1180 out of 2268\n",
            "1181 out of 2268\n",
            "1182 out of 2268\n",
            "1183 out of 2268\n",
            "1184 out of 2268\n",
            "1185 out of 2268\n",
            "1186 out of 2268\n",
            "1187 out of 2268\n",
            "1188 out of 2268\n",
            "1189 out of 2268\n",
            "1190 out of 2268\n",
            "1191 out of 2268\n",
            "1192 out of 2268\n",
            "1193 out of 2268\n",
            "1194 out of 2268\n",
            "1195 out of 2268\n",
            "1196 out of 2268\n",
            "1197 out of 2268\n",
            "1198 out of 2268\n",
            "1199 out of 2268\n",
            "1200 out of 2268\n",
            "1201 out of 2268\n",
            "1202 out of 2268\n",
            "1203 out of 2268\n",
            "1204 out of 2268\n",
            "1205 out of 2268\n",
            "1206 out of 2268\n",
            "1207 out of 2268\n",
            "1208 out of 2268\n",
            "1209 out of 2268\n",
            "1210 out of 2268\n",
            "1211 out of 2268\n",
            "1212 out of 2268\n",
            "1213 out of 2268\n",
            "1214 out of 2268\n",
            "1215 out of 2268\n",
            "1216 out of 2268\n",
            "1217 out of 2268\n",
            "1218 out of 2268\n",
            "1219 out of 2268\n",
            "1220 out of 2268\n",
            "1221 out of 2268\n",
            "1222 out of 2268\n",
            "1223 out of 2268\n",
            "1224 out of 2268\n",
            "1225 out of 2268\n",
            "1226 out of 2268\n",
            "1227 out of 2268\n",
            "1228 out of 2268\n",
            "1229 out of 2268\n",
            "1230 out of 2268\n",
            "1231 out of 2268\n",
            "1232 out of 2268\n",
            "1233 out of 2268\n",
            "1234 out of 2268\n",
            "1235 out of 2268\n",
            "1236 out of 2268\n",
            "1237 out of 2268\n",
            "1238 out of 2268\n",
            "1239 out of 2268\n",
            "1240 out of 2268\n",
            "1241 out of 2268\n",
            "1242 out of 2268\n",
            "1243 out of 2268\n",
            "1244 out of 2268\n",
            "1245 out of 2268\n",
            "1246 out of 2268\n",
            "1247 out of 2268\n",
            "1248 out of 2268\n",
            "1249 out of 2268\n",
            "1250 out of 2268\n",
            "1251 out of 2268\n",
            "1252 out of 2268\n",
            "1253 out of 2268\n",
            "1254 out of 2268\n",
            "1255 out of 2268\n",
            "1256 out of 2268\n",
            "1257 out of 2268\n",
            "1258 out of 2268\n",
            "1259 out of 2268\n",
            "1260 out of 2268\n",
            "1261 out of 2268\n",
            "1262 out of 2268\n",
            "1263 out of 2268\n",
            "1264 out of 2268\n",
            "1265 out of 2268\n",
            "1266 out of 2268\n",
            "1267 out of 2268\n",
            "1268 out of 2268\n",
            "1269 out of 2268\n",
            "1270 out of 2268\n",
            "1271 out of 2268\n",
            "1272 out of 2268\n",
            "1273 out of 2268\n",
            "1274 out of 2268\n",
            "1275 out of 2268\n",
            "1276 out of 2268\n",
            "1277 out of 2268\n",
            "1278 out of 2268\n",
            "1279 out of 2268\n",
            "1280 out of 2268\n",
            "1281 out of 2268\n",
            "1282 out of 2268\n",
            "1283 out of 2268\n",
            "1284 out of 2268\n",
            "1285 out of 2268\n",
            "1286 out of 2268\n",
            "1287 out of 2268\n",
            "1288 out of 2268\n",
            "1289 out of 2268\n",
            "1290 out of 2268\n",
            "1291 out of 2268\n",
            "1292 out of 2268\n",
            "1293 out of 2268\n",
            "1294 out of 2268\n",
            "1295 out of 2268\n",
            "1296 out of 2268\n",
            "1297 out of 2268\n",
            "1298 out of 2268\n",
            "1299 out of 2268\n",
            "1300 out of 2268\n",
            "1301 out of 2268\n",
            "1302 out of 2268\n",
            "1303 out of 2268\n",
            "1304 out of 2268\n",
            "1305 out of 2268\n",
            "1306 out of 2268\n",
            "1307 out of 2268\n",
            "1308 out of 2268\n",
            "1309 out of 2268\n",
            "1310 out of 2268\n",
            "1311 out of 2268\n",
            "1312 out of 2268\n",
            "1313 out of 2268\n",
            "1314 out of 2268\n",
            "1315 out of 2268\n",
            "1316 out of 2268\n",
            "1317 out of 2268\n",
            "1318 out of 2268\n",
            "1319 out of 2268\n",
            "1320 out of 2268\n",
            "1321 out of 2268\n",
            "1322 out of 2268\n",
            "1323 out of 2268\n",
            "1324 out of 2268\n",
            "1325 out of 2268\n",
            "1326 out of 2268\n",
            "1327 out of 2268\n",
            "1328 out of 2268\n",
            "1329 out of 2268\n",
            "1330 out of 2268\n",
            "1331 out of 2268\n",
            "1332 out of 2268\n",
            "1333 out of 2268\n",
            "1334 out of 2268\n",
            "1335 out of 2268\n",
            "1336 out of 2268\n",
            "1337 out of 2268\n",
            "1338 out of 2268\n",
            "1339 out of 2268\n",
            "1340 out of 2268\n",
            "1341 out of 2268\n",
            "1342 out of 2268\n",
            "1343 out of 2268\n",
            "1344 out of 2268\n",
            "1345 out of 2268\n",
            "1346 out of 2268\n",
            "1347 out of 2268\n",
            "1348 out of 2268\n",
            "1349 out of 2268\n",
            "1350 out of 2268\n",
            "1351 out of 2268\n",
            "1352 out of 2268\n",
            "1353 out of 2268\n",
            "1354 out of 2268\n",
            "1355 out of 2268\n",
            "1356 out of 2268\n",
            "1357 out of 2268\n",
            "1358 out of 2268\n",
            "1359 out of 2268\n",
            "1360 out of 2268\n",
            "1361 out of 2268\n",
            "1362 out of 2268\n",
            "1363 out of 2268\n",
            "1364 out of 2268\n",
            "1365 out of 2268\n",
            "1366 out of 2268\n",
            "1367 out of 2268\n",
            "1368 out of 2268\n",
            "1369 out of 2268\n",
            "1370 out of 2268\n",
            "1371 out of 2268\n",
            "1372 out of 2268\n",
            "1373 out of 2268\n",
            "1374 out of 2268\n",
            "1375 out of 2268\n",
            "1376 out of 2268\n",
            "1377 out of 2268\n",
            "1378 out of 2268\n",
            "1379 out of 2268\n",
            "1380 out of 2268\n",
            "1381 out of 2268\n",
            "1382 out of 2268\n",
            "1383 out of 2268\n",
            "1384 out of 2268\n",
            "1385 out of 2268\n",
            "1386 out of 2268\n",
            "1387 out of 2268\n",
            "1388 out of 2268\n",
            "1389 out of 2268\n",
            "1390 out of 2268\n",
            "1391 out of 2268\n",
            "1392 out of 2268\n",
            "1393 out of 2268\n",
            "1394 out of 2268\n",
            "1395 out of 2268\n",
            "1396 out of 2268\n",
            "1397 out of 2268\n",
            "1398 out of 2268\n",
            "1399 out of 2268\n",
            "1400 out of 2268\n",
            "1401 out of 2268\n",
            "1402 out of 2268\n",
            "1403 out of 2268\n",
            "1404 out of 2268\n",
            "1405 out of 2268\n",
            "1406 out of 2268\n",
            "1407 out of 2268\n",
            "1408 out of 2268\n",
            "1409 out of 2268\n",
            "1410 out of 2268\n",
            "1411 out of 2268\n",
            "1412 out of 2268\n",
            "1413 out of 2268\n",
            "1414 out of 2268\n",
            "1415 out of 2268\n",
            "1416 out of 2268\n",
            "1417 out of 2268\n",
            "1418 out of 2268\n",
            "1419 out of 2268\n",
            "1420 out of 2268\n",
            "1421 out of 2268\n",
            "1422 out of 2268\n",
            "1423 out of 2268\n",
            "1424 out of 2268\n",
            "1425 out of 2268\n",
            "1426 out of 2268\n",
            "1427 out of 2268\n",
            "1428 out of 2268\n",
            "1429 out of 2268\n",
            "1430 out of 2268\n",
            "1431 out of 2268\n",
            "1432 out of 2268\n",
            "1433 out of 2268\n",
            "1434 out of 2268\n",
            "1435 out of 2268\n",
            "1436 out of 2268\n",
            "1437 out of 2268\n",
            "1438 out of 2268\n",
            "1439 out of 2268\n",
            "1440 out of 2268\n",
            "1441 out of 2268\n",
            "1442 out of 2268\n",
            "1443 out of 2268\n",
            "1444 out of 2268\n",
            "1445 out of 2268\n",
            "1446 out of 2268\n",
            "1447 out of 2268\n",
            "1448 out of 2268\n",
            "1449 out of 2268\n",
            "1450 out of 2268\n",
            "1451 out of 2268\n",
            "1452 out of 2268\n",
            "1453 out of 2268\n",
            "1454 out of 2268\n",
            "1455 out of 2268\n",
            "1456 out of 2268\n",
            "1457 out of 2268\n",
            "1458 out of 2268\n",
            "1459 out of 2268\n",
            "1460 out of 2268\n",
            "1461 out of 2268\n",
            "1462 out of 2268\n",
            "1463 out of 2268\n",
            "1464 out of 2268\n",
            "1465 out of 2268\n",
            "1466 out of 2268\n",
            "1467 out of 2268\n",
            "1468 out of 2268\n",
            "1469 out of 2268\n",
            "1470 out of 2268\n",
            "1471 out of 2268\n",
            "1472 out of 2268\n",
            "1473 out of 2268\n",
            "1474 out of 2268\n",
            "1475 out of 2268\n",
            "1476 out of 2268\n",
            "1477 out of 2268\n",
            "1478 out of 2268\n",
            "1479 out of 2268\n",
            "1480 out of 2268\n",
            "1481 out of 2268\n",
            "1482 out of 2268\n",
            "1483 out of 2268\n",
            "1484 out of 2268\n",
            "1485 out of 2268\n",
            "1486 out of 2268\n",
            "1487 out of 2268\n",
            "1488 out of 2268\n",
            "1489 out of 2268\n",
            "1490 out of 2268\n",
            "1491 out of 2268\n",
            "1492 out of 2268\n",
            "1493 out of 2268\n",
            "1494 out of 2268\n",
            "1495 out of 2268\n",
            "1496 out of 2268\n",
            "1497 out of 2268\n",
            "1498 out of 2268\n",
            "1499 out of 2268\n",
            "1500 out of 2268\n",
            "1501 out of 2268\n",
            "1502 out of 2268\n",
            "1503 out of 2268\n",
            "1504 out of 2268\n",
            "1505 out of 2268\n",
            "1506 out of 2268\n",
            "1507 out of 2268\n",
            "1508 out of 2268\n",
            "1509 out of 2268\n",
            "1510 out of 2268\n",
            "1511 out of 2268\n",
            "1512 out of 2268\n",
            "1513 out of 2268\n",
            "1514 out of 2268\n",
            "1515 out of 2268\n",
            "1516 out of 2268\n",
            "1517 out of 2268\n",
            "1518 out of 2268\n",
            "1519 out of 2268\n",
            "1520 out of 2268\n",
            "1521 out of 2268\n",
            "1522 out of 2268\n",
            "1523 out of 2268\n",
            "1524 out of 2268\n",
            "1525 out of 2268\n",
            "1526 out of 2268\n",
            "1527 out of 2268\n",
            "1528 out of 2268\n",
            "1529 out of 2268\n",
            "1530 out of 2268\n",
            "1531 out of 2268\n",
            "1532 out of 2268\n",
            "1533 out of 2268\n",
            "1534 out of 2268\n",
            "1535 out of 2268\n",
            "1536 out of 2268\n",
            "1537 out of 2268\n",
            "1538 out of 2268\n",
            "1539 out of 2268\n",
            "1540 out of 2268\n",
            "1541 out of 2268\n",
            "1542 out of 2268\n",
            "1543 out of 2268\n",
            "1544 out of 2268\n",
            "1545 out of 2268\n",
            "1546 out of 2268\n",
            "1547 out of 2268\n",
            "1548 out of 2268\n",
            "1549 out of 2268\n",
            "1550 out of 2268\n",
            "1551 out of 2268\n",
            "1552 out of 2268\n",
            "1553 out of 2268\n",
            "1554 out of 2268\n",
            "1555 out of 2268\n",
            "1556 out of 2268\n",
            "1557 out of 2268\n",
            "1558 out of 2268\n",
            "1559 out of 2268\n",
            "1560 out of 2268\n",
            "1561 out of 2268\n",
            "1562 out of 2268\n",
            "1563 out of 2268\n",
            "1564 out of 2268\n",
            "1565 out of 2268\n",
            "1566 out of 2268\n",
            "1567 out of 2268\n",
            "1568 out of 2268\n",
            "1569 out of 2268\n",
            "1570 out of 2268\n",
            "1571 out of 2268\n",
            "1572 out of 2268\n",
            "1573 out of 2268\n",
            "1574 out of 2268\n",
            "1575 out of 2268\n",
            "1576 out of 2268\n",
            "1577 out of 2268\n",
            "1578 out of 2268\n",
            "1579 out of 2268\n",
            "1580 out of 2268\n",
            "1581 out of 2268\n",
            "1582 out of 2268\n",
            "1583 out of 2268\n",
            "1584 out of 2268\n",
            "1585 out of 2268\n",
            "1586 out of 2268\n",
            "1587 out of 2268\n",
            "1588 out of 2268\n",
            "1589 out of 2268\n",
            "1590 out of 2268\n",
            "1591 out of 2268\n",
            "1592 out of 2268\n",
            "1593 out of 2268\n",
            "1594 out of 2268\n",
            "1595 out of 2268\n",
            "1596 out of 2268\n",
            "1597 out of 2268\n",
            "1598 out of 2268\n",
            "1599 out of 2268\n",
            "1600 out of 2268\n",
            "1601 out of 2268\n",
            "1602 out of 2268\n",
            "1603 out of 2268\n",
            "1604 out of 2268\n",
            "1605 out of 2268\n",
            "1606 out of 2268\n",
            "1607 out of 2268\n",
            "1608 out of 2268\n",
            "1609 out of 2268\n",
            "1610 out of 2268\n",
            "1611 out of 2268\n",
            "1612 out of 2268\n",
            "1613 out of 2268\n",
            "1614 out of 2268\n",
            "1615 out of 2268\n",
            "1616 out of 2268\n",
            "1617 out of 2268\n",
            "1618 out of 2268\n",
            "1619 out of 2268\n",
            "1620 out of 2268\n",
            "1621 out of 2268\n",
            "1622 out of 2268\n",
            "1623 out of 2268\n",
            "1624 out of 2268\n",
            "1625 out of 2268\n",
            "1626 out of 2268\n",
            "1627 out of 2268\n",
            "1628 out of 2268\n",
            "1629 out of 2268\n",
            "1630 out of 2268\n",
            "1631 out of 2268\n",
            "1632 out of 2268\n",
            "1633 out of 2268\n",
            "1634 out of 2268\n",
            "1635 out of 2268\n",
            "1636 out of 2268\n",
            "1637 out of 2268\n",
            "1638 out of 2268\n",
            "1639 out of 2268\n",
            "1640 out of 2268\n",
            "1641 out of 2268\n",
            "1642 out of 2268\n",
            "1643 out of 2268\n",
            "1644 out of 2268\n",
            "1645 out of 2268\n",
            "1646 out of 2268\n",
            "1647 out of 2268\n",
            "1648 out of 2268\n",
            "1649 out of 2268\n",
            "1650 out of 2268\n",
            "1651 out of 2268\n",
            "1652 out of 2268\n",
            "1653 out of 2268\n",
            "1654 out of 2268\n",
            "1655 out of 2268\n",
            "1656 out of 2268\n",
            "1657 out of 2268\n",
            "1658 out of 2268\n",
            "1659 out of 2268\n",
            "1660 out of 2268\n",
            "1661 out of 2268\n",
            "1662 out of 2268\n",
            "1663 out of 2268\n",
            "1664 out of 2268\n",
            "1665 out of 2268\n",
            "1666 out of 2268\n",
            "1667 out of 2268\n",
            "1668 out of 2268\n",
            "1669 out of 2268\n",
            "1670 out of 2268\n",
            "1671 out of 2268\n",
            "1672 out of 2268\n",
            "1673 out of 2268\n",
            "1674 out of 2268\n",
            "1675 out of 2268\n",
            "1676 out of 2268\n",
            "1677 out of 2268\n",
            "1678 out of 2268\n",
            "1679 out of 2268\n",
            "1680 out of 2268\n",
            "1681 out of 2268\n",
            "1682 out of 2268\n",
            "1683 out of 2268\n",
            "1684 out of 2268\n",
            "1685 out of 2268\n",
            "1686 out of 2268\n",
            "1687 out of 2268\n",
            "1688 out of 2268\n",
            "1689 out of 2268\n",
            "1690 out of 2268\n",
            "1691 out of 2268\n",
            "1692 out of 2268\n",
            "1693 out of 2268\n",
            "1694 out of 2268\n",
            "1695 out of 2268\n",
            "1696 out of 2268\n",
            "1697 out of 2268\n",
            "1698 out of 2268\n",
            "1699 out of 2268\n",
            "1700 out of 2268\n",
            "1701 out of 2268\n",
            "1702 out of 2268\n",
            "1703 out of 2268\n",
            "1704 out of 2268\n",
            "1705 out of 2268\n",
            "1706 out of 2268\n",
            "1707 out of 2268\n",
            "1708 out of 2268\n",
            "1709 out of 2268\n",
            "1710 out of 2268\n",
            "1711 out of 2268\n",
            "1712 out of 2268\n",
            "1713 out of 2268\n",
            "1714 out of 2268\n",
            "1715 out of 2268\n",
            "1716 out of 2268\n",
            "1717 out of 2268\n",
            "1718 out of 2268\n",
            "1719 out of 2268\n",
            "1720 out of 2268\n",
            "1721 out of 2268\n",
            "1722 out of 2268\n",
            "1723 out of 2268\n",
            "1724 out of 2268\n",
            "1725 out of 2268\n",
            "1726 out of 2268\n",
            "1727 out of 2268\n",
            "1728 out of 2268\n",
            "1729 out of 2268\n",
            "1730 out of 2268\n",
            "1731 out of 2268\n",
            "1732 out of 2268\n",
            "1733 out of 2268\n",
            "1734 out of 2268\n",
            "1735 out of 2268\n",
            "1736 out of 2268\n",
            "1737 out of 2268\n",
            "1738 out of 2268\n",
            "1739 out of 2268\n",
            "1740 out of 2268\n",
            "1741 out of 2268\n",
            "1742 out of 2268\n",
            "1743 out of 2268\n",
            "1744 out of 2268\n",
            "1745 out of 2268\n",
            "1746 out of 2268\n",
            "1747 out of 2268\n",
            "1748 out of 2268\n",
            "1749 out of 2268\n",
            "1750 out of 2268\n",
            "1751 out of 2268\n",
            "1752 out of 2268\n",
            "1753 out of 2268\n",
            "1754 out of 2268\n",
            "1755 out of 2268\n",
            "1756 out of 2268\n",
            "1757 out of 2268\n",
            "1758 out of 2268\n",
            "1759 out of 2268\n",
            "1760 out of 2268\n",
            "1761 out of 2268\n",
            "1762 out of 2268\n",
            "1763 out of 2268\n",
            "1764 out of 2268\n",
            "1765 out of 2268\n",
            "1766 out of 2268\n",
            "1767 out of 2268\n",
            "1768 out of 2268\n",
            "1769 out of 2268\n",
            "1770 out of 2268\n",
            "1771 out of 2268\n",
            "1772 out of 2268\n",
            "1773 out of 2268\n",
            "1774 out of 2268\n",
            "1775 out of 2268\n",
            "1776 out of 2268\n",
            "1777 out of 2268\n",
            "1778 out of 2268\n",
            "1779 out of 2268\n",
            "1780 out of 2268\n",
            "1781 out of 2268\n",
            "1782 out of 2268\n",
            "1783 out of 2268\n",
            "1784 out of 2268\n",
            "1785 out of 2268\n",
            "1786 out of 2268\n",
            "1787 out of 2268\n",
            "1788 out of 2268\n",
            "1789 out of 2268\n",
            "1790 out of 2268\n",
            "1791 out of 2268\n",
            "1792 out of 2268\n",
            "1793 out of 2268\n",
            "1794 out of 2268\n",
            "1795 out of 2268\n",
            "1796 out of 2268\n",
            "1797 out of 2268\n",
            "1798 out of 2268\n",
            "1799 out of 2268\n",
            "1800 out of 2268\n",
            "1801 out of 2268\n",
            "1802 out of 2268\n",
            "1803 out of 2268\n",
            "1804 out of 2268\n",
            "1805 out of 2268\n",
            "1806 out of 2268\n",
            "1807 out of 2268\n",
            "1808 out of 2268\n",
            "1809 out of 2268\n",
            "1810 out of 2268\n",
            "1811 out of 2268\n",
            "1812 out of 2268\n",
            "1813 out of 2268\n",
            "1814 out of 2268\n",
            "1815 out of 2268\n",
            "1816 out of 2268\n",
            "1817 out of 2268\n",
            "1818 out of 2268\n",
            "1819 out of 2268\n",
            "1820 out of 2268\n",
            "1821 out of 2268\n",
            "1822 out of 2268\n",
            "1823 out of 2268\n",
            "1824 out of 2268\n",
            "1825 out of 2268\n",
            "1826 out of 2268\n",
            "1827 out of 2268\n",
            "1828 out of 2268\n",
            "1829 out of 2268\n",
            "1830 out of 2268\n",
            "1831 out of 2268\n",
            "1832 out of 2268\n",
            "1833 out of 2268\n",
            "1834 out of 2268\n",
            "1835 out of 2268\n",
            "1836 out of 2268\n",
            "1837 out of 2268\n",
            "1838 out of 2268\n",
            "1839 out of 2268\n",
            "1840 out of 2268\n",
            "1841 out of 2268\n",
            "1842 out of 2268\n",
            "1843 out of 2268\n",
            "1844 out of 2268\n",
            "1845 out of 2268\n",
            "1846 out of 2268\n",
            "1847 out of 2268\n",
            "1848 out of 2268\n",
            "1849 out of 2268\n",
            "1850 out of 2268\n",
            "1851 out of 2268\n",
            "1852 out of 2268\n",
            "1853 out of 2268\n",
            "1854 out of 2268\n",
            "1855 out of 2268\n",
            "1856 out of 2268\n",
            "1857 out of 2268\n",
            "1858 out of 2268\n",
            "1859 out of 2268\n",
            "1860 out of 2268\n",
            "1861 out of 2268\n",
            "1862 out of 2268\n",
            "1863 out of 2268\n",
            "1864 out of 2268\n",
            "1865 out of 2268\n",
            "1866 out of 2268\n",
            "1867 out of 2268\n",
            "1868 out of 2268\n",
            "1869 out of 2268\n",
            "1870 out of 2268\n",
            "1871 out of 2268\n",
            "1872 out of 2268\n",
            "1873 out of 2268\n",
            "1874 out of 2268\n",
            "1875 out of 2268\n",
            "1876 out of 2268\n",
            "1877 out of 2268\n",
            "1878 out of 2268\n",
            "1879 out of 2268\n",
            "1880 out of 2268\n",
            "1881 out of 2268\n",
            "1882 out of 2268\n",
            "1883 out of 2268\n",
            "1884 out of 2268\n",
            "1885 out of 2268\n",
            "1886 out of 2268\n",
            "1887 out of 2268\n",
            "1888 out of 2268\n",
            "1889 out of 2268\n",
            "1890 out of 2268\n",
            "1891 out of 2268\n",
            "1892 out of 2268\n",
            "1893 out of 2268\n",
            "1894 out of 2268\n",
            "1895 out of 2268\n",
            "1896 out of 2268\n",
            "1897 out of 2268\n",
            "1898 out of 2268\n",
            "1899 out of 2268\n",
            "1900 out of 2268\n",
            "1901 out of 2268\n",
            "1902 out of 2268\n",
            "1903 out of 2268\n",
            "1904 out of 2268\n",
            "1905 out of 2268\n",
            "1906 out of 2268\n",
            "1907 out of 2268\n",
            "1908 out of 2268\n",
            "1909 out of 2268\n",
            "1910 out of 2268\n",
            "1911 out of 2268\n",
            "1912 out of 2268\n",
            "1913 out of 2268\n",
            "1914 out of 2268\n",
            "1915 out of 2268\n",
            "1916 out of 2268\n",
            "1917 out of 2268\n",
            "1918 out of 2268\n",
            "1919 out of 2268\n",
            "1920 out of 2268\n",
            "1921 out of 2268\n",
            "1922 out of 2268\n",
            "1923 out of 2268\n",
            "1924 out of 2268\n",
            "1925 out of 2268\n",
            "1926 out of 2268\n",
            "1927 out of 2268\n",
            "1928 out of 2268\n",
            "1929 out of 2268\n",
            "1930 out of 2268\n",
            "1931 out of 2268\n",
            "1932 out of 2268\n",
            "1933 out of 2268\n",
            "1934 out of 2268\n",
            "1935 out of 2268\n",
            "1936 out of 2268\n",
            "1937 out of 2268\n",
            "1938 out of 2268\n",
            "1939 out of 2268\n",
            "1940 out of 2268\n",
            "1941 out of 2268\n",
            "1942 out of 2268\n",
            "1943 out of 2268\n",
            "1944 out of 2268\n",
            "1945 out of 2268\n",
            "1946 out of 2268\n",
            "1947 out of 2268\n",
            "1948 out of 2268\n",
            "1949 out of 2268\n",
            "1950 out of 2268\n",
            "1951 out of 2268\n",
            "1952 out of 2268\n",
            "1953 out of 2268\n",
            "1954 out of 2268\n",
            "1955 out of 2268\n",
            "1956 out of 2268\n",
            "1957 out of 2268\n",
            "1958 out of 2268\n",
            "1959 out of 2268\n",
            "1960 out of 2268\n",
            "1961 out of 2268\n",
            "1962 out of 2268\n",
            "1963 out of 2268\n",
            "1964 out of 2268\n",
            "1965 out of 2268\n",
            "1966 out of 2268\n",
            "1967 out of 2268\n",
            "1968 out of 2268\n",
            "1969 out of 2268\n",
            "1970 out of 2268\n",
            "1971 out of 2268\n",
            "1972 out of 2268\n",
            "1973 out of 2268\n",
            "1974 out of 2268\n",
            "1975 out of 2268\n",
            "1976 out of 2268\n",
            "1977 out of 2268\n",
            "1978 out of 2268\n",
            "1979 out of 2268\n",
            "1980 out of 2268\n",
            "1981 out of 2268\n",
            "1982 out of 2268\n",
            "1983 out of 2268\n",
            "1984 out of 2268\n",
            "1985 out of 2268\n",
            "1986 out of 2268\n",
            "1987 out of 2268\n",
            "1988 out of 2268\n",
            "1989 out of 2268\n",
            "1990 out of 2268\n",
            "1991 out of 2268\n",
            "1992 out of 2268\n",
            "1993 out of 2268\n",
            "1994 out of 2268\n",
            "1995 out of 2268\n",
            "1996 out of 2268\n",
            "1997 out of 2268\n",
            "1998 out of 2268\n",
            "1999 out of 2268\n",
            "2000 out of 2268\n",
            "2001 out of 2268\n",
            "2002 out of 2268\n",
            "2003 out of 2268\n",
            "2004 out of 2268\n",
            "2005 out of 2268\n",
            "2006 out of 2268\n",
            "2007 out of 2268\n",
            "2008 out of 2268\n",
            "2009 out of 2268\n",
            "2010 out of 2268\n",
            "2011 out of 2268\n",
            "2012 out of 2268\n",
            "2013 out of 2268\n",
            "2014 out of 2268\n",
            "2015 out of 2268\n",
            "2016 out of 2268\n",
            "2017 out of 2268\n",
            "2018 out of 2268\n",
            "2019 out of 2268\n",
            "2020 out of 2268\n",
            "2021 out of 2268\n",
            "2022 out of 2268\n",
            "2023 out of 2268\n",
            "2024 out of 2268\n",
            "2025 out of 2268\n",
            "2026 out of 2268\n",
            "2027 out of 2268\n",
            "2028 out of 2268\n",
            "2029 out of 2268\n",
            "2030 out of 2268\n",
            "2031 out of 2268\n",
            "2032 out of 2268\n",
            "2033 out of 2268\n",
            "2034 out of 2268\n",
            "2035 out of 2268\n",
            "2036 out of 2268\n",
            "2037 out of 2268\n",
            "2038 out of 2268\n",
            "2039 out of 2268\n",
            "2040 out of 2268\n",
            "2041 out of 2268\n",
            "2042 out of 2268\n",
            "2043 out of 2268\n",
            "2044 out of 2268\n",
            "2045 out of 2268\n",
            "2046 out of 2268\n",
            "2047 out of 2268\n",
            "2048 out of 2268\n",
            "2049 out of 2268\n",
            "2050 out of 2268\n",
            "2051 out of 2268\n",
            "2052 out of 2268\n",
            "2053 out of 2268\n",
            "2054 out of 2268\n",
            "2055 out of 2268\n",
            "2056 out of 2268\n",
            "2057 out of 2268\n",
            "2058 out of 2268\n",
            "2059 out of 2268\n",
            "2060 out of 2268\n",
            "2061 out of 2268\n",
            "2062 out of 2268\n",
            "2063 out of 2268\n",
            "2064 out of 2268\n",
            "2065 out of 2268\n",
            "2066 out of 2268\n",
            "2067 out of 2268\n",
            "2068 out of 2268\n",
            "2069 out of 2268\n",
            "2070 out of 2268\n",
            "2071 out of 2268\n",
            "2072 out of 2268\n",
            "2073 out of 2268\n",
            "2074 out of 2268\n",
            "2075 out of 2268\n",
            "2076 out of 2268\n",
            "2077 out of 2268\n",
            "2078 out of 2268\n",
            "2079 out of 2268\n",
            "2080 out of 2268\n",
            "2081 out of 2268\n",
            "2082 out of 2268\n",
            "2083 out of 2268\n",
            "2084 out of 2268\n",
            "2085 out of 2268\n",
            "2086 out of 2268\n",
            "2087 out of 2268\n",
            "2088 out of 2268\n",
            "2089 out of 2268\n",
            "2090 out of 2268\n",
            "2091 out of 2268\n",
            "2092 out of 2268\n",
            "2093 out of 2268\n",
            "2094 out of 2268\n",
            "2095 out of 2268\n",
            "2096 out of 2268\n",
            "2097 out of 2268\n",
            "2098 out of 2268\n",
            "2099 out of 2268\n",
            "2100 out of 2268\n",
            "2101 out of 2268\n",
            "2102 out of 2268\n",
            "2103 out of 2268\n",
            "2104 out of 2268\n",
            "2105 out of 2268\n",
            "2106 out of 2268\n",
            "2107 out of 2268\n",
            "2108 out of 2268\n",
            "2109 out of 2268\n",
            "2110 out of 2268\n",
            "2111 out of 2268\n",
            "2112 out of 2268\n",
            "2113 out of 2268\n",
            "2114 out of 2268\n",
            "2115 out of 2268\n",
            "2116 out of 2268\n",
            "2117 out of 2268\n",
            "2118 out of 2268\n",
            "2119 out of 2268\n",
            "2120 out of 2268\n",
            "2121 out of 2268\n",
            "2122 out of 2268\n",
            "2123 out of 2268\n",
            "2124 out of 2268\n",
            "2125 out of 2268\n",
            "2126 out of 2268\n",
            "2127 out of 2268\n",
            "2128 out of 2268\n",
            "2129 out of 2268\n",
            "2130 out of 2268\n",
            "2131 out of 2268\n",
            "2132 out of 2268\n",
            "2133 out of 2268\n",
            "2134 out of 2268\n",
            "2135 out of 2268\n",
            "2136 out of 2268\n",
            "2137 out of 2268\n",
            "2138 out of 2268\n",
            "2139 out of 2268\n",
            "2140 out of 2268\n",
            "2141 out of 2268\n",
            "2142 out of 2268\n",
            "2143 out of 2268\n",
            "2144 out of 2268\n",
            "2145 out of 2268\n",
            "2146 out of 2268\n",
            "2147 out of 2268\n",
            "2148 out of 2268\n",
            "2149 out of 2268\n",
            "2150 out of 2268\n",
            "2151 out of 2268\n",
            "2152 out of 2268\n",
            "2153 out of 2268\n",
            "2154 out of 2268\n",
            "2155 out of 2268\n",
            "2156 out of 2268\n",
            "2157 out of 2268\n",
            "2158 out of 2268\n",
            "2159 out of 2268\n",
            "2160 out of 2268\n",
            "2161 out of 2268\n",
            "2162 out of 2268\n",
            "2163 out of 2268\n",
            "2164 out of 2268\n",
            "2165 out of 2268\n",
            "2166 out of 2268\n",
            "2167 out of 2268\n",
            "2168 out of 2268\n",
            "2169 out of 2268\n",
            "2170 out of 2268\n",
            "2171 out of 2268\n",
            "2172 out of 2268\n",
            "2173 out of 2268\n",
            "2174 out of 2268\n",
            "2175 out of 2268\n",
            "2176 out of 2268\n",
            "2177 out of 2268\n",
            "2178 out of 2268\n",
            "2179 out of 2268\n",
            "2180 out of 2268\n",
            "2181 out of 2268\n",
            "2182 out of 2268\n",
            "2183 out of 2268\n",
            "2184 out of 2268\n",
            "2185 out of 2268\n",
            "2186 out of 2268\n",
            "2187 out of 2268\n",
            "2188 out of 2268\n",
            "2189 out of 2268\n",
            "2190 out of 2268\n",
            "2191 out of 2268\n",
            "2192 out of 2268\n",
            "2193 out of 2268\n",
            "2194 out of 2268\n",
            "2195 out of 2268\n",
            "2196 out of 2268\n",
            "2197 out of 2268\n",
            "2198 out of 2268\n",
            "2199 out of 2268\n",
            "2200 out of 2268\n",
            "2201 out of 2268\n",
            "2202 out of 2268\n",
            "2203 out of 2268\n",
            "2204 out of 2268\n",
            "2205 out of 2268\n",
            "2206 out of 2268\n",
            "2207 out of 2268\n",
            "2208 out of 2268\n",
            "2209 out of 2268\n",
            "2210 out of 2268\n",
            "2211 out of 2268\n",
            "2212 out of 2268\n",
            "2213 out of 2268\n",
            "2214 out of 2268\n",
            "2215 out of 2268\n",
            "2216 out of 2268\n",
            "2217 out of 2268\n",
            "2218 out of 2268\n",
            "2219 out of 2268\n",
            "2220 out of 2268\n",
            "2221 out of 2268\n",
            "2222 out of 2268\n",
            "2223 out of 2268\n",
            "2224 out of 2268\n",
            "2225 out of 2268\n",
            "2226 out of 2268\n",
            "2227 out of 2268\n",
            "2228 out of 2268\n",
            "2229 out of 2268\n",
            "2230 out of 2268\n",
            "2231 out of 2268\n",
            "2232 out of 2268\n",
            "2233 out of 2268\n",
            "2234 out of 2268\n",
            "2235 out of 2268\n",
            "2236 out of 2268\n",
            "2237 out of 2268\n",
            "2238 out of 2268\n",
            "2239 out of 2268\n",
            "2240 out of 2268\n",
            "2241 out of 2268\n",
            "2242 out of 2268\n",
            "2243 out of 2268\n",
            "2244 out of 2268\n",
            "2245 out of 2268\n",
            "2246 out of 2268\n",
            "2247 out of 2268\n",
            "2248 out of 2268\n",
            "2249 out of 2268\n",
            "2250 out of 2268\n",
            "2251 out of 2268\n",
            "2252 out of 2268\n",
            "2253 out of 2268\n",
            "2254 out of 2268\n",
            "2255 out of 2268\n",
            "2256 out of 2268\n",
            "2257 out of 2268\n",
            "2258 out of 2268\n",
            "2259 out of 2268\n",
            "2260 out of 2268\n",
            "2261 out of 2268\n",
            "2262 out of 2268\n",
            "2263 out of 2268\n",
            "2264 out of 2268\n",
            "2265 out of 2268\n",
            "2266 out of 2268\n",
            "2267 out of 2268\n",
            "2268 out of 2268\n"
          ]
        }
      ],
      "source": [
        "# 开始回归\n",
        "start = time.perf_counter()\n",
        "for i in sub_df['del_lag1'].tolist():\n",
        "    print('%d out of %d' %(sub_df['del_lag1'].tolist().index(i)+1,len(sub_df['del_lag1'].tolist())))\n",
        "    i_lst = list(i)\n",
        "    x = X[i_lst] \n",
        "    #计算vif系数\n",
        "    x_vif = copy.deepcopy(x)\n",
        "    x_vif['constant'] = 1\n",
        "    x_vif = x_vif.dropna()\n",
        "    vif_values = []\n",
        "    for j in range(len(i_lst)):\n",
        "        vif_values.append(variance_inflation_factor(x_vif.loc[x.index[lag]:,i_lst].values,j))\n",
        "        \n",
        "    x = sm.add_constant(x)\n",
        "    model = sm.OLS(y,x,missing='drop')\n",
        "    results = model.fit()\n",
        "    if len(i_lst) < paranum:\n",
        "        gap = copy.deepcopy((paranum-len(i_lst)))\n",
        "        i_lst.extend([\"\"]*gap)\n",
        "        reg = pd.DataFrame(np.array(i_lst+results.params.tolist()+[\"\"]*gap+results.pvalues.tolist()+[\"\"]*gap+[results.rsquared,]+vif_values).reshape(1,paranum*4+3),columns=regresults_colst)\n",
        "    else:\n",
        "        reg = pd.DataFrame(np.array(i_lst+results.params.tolist()+results.pvalues.tolist()+[results.rsquared,]+vif_values).reshape(1,paranum*4+3),columns=regresults_colst)\n",
        "    \n",
        "    regresults = regresults.append(reg,ignore_index=True)\n",
        "end = time.perf_counter()"
      ],
      "id": "hVN1AZMqRjuo"
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "vGhKO9dARjuo",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de5004a-3f34-42f6-8717-9253e593dadd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "回归2268组方程用时34.112621279999075秒\n"
          ]
        }
      ],
      "source": [
        "print ('回归%d组方程用时%s秒' %(len(sub_df),end-start))"
      ],
      "id": "vGhKO9dARjuo"
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "c4GcbjPURjup"
      },
      "outputs": [],
      "source": [
        "## 把所有regresults的系数、p值和R^2转化成数值\n",
        "regresults[betalst+plst+[u'R2']+viflst] = regresults[betalst+plst+[u'R2']+viflst].applymap(lambda x:float(x)) "
      ],
      "id": "c4GcbjPURjup"
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "vP_GnH9rRjup"
      },
      "outputs": [],
      "source": [
        "# 根据系数经济含义\\p统计量\\vif小于阈值\\以及R^2最大筛选模型 \n",
        "# 构造regresults新列，去掉L前缀\n",
        "def delL(string):\n",
        "    \n",
        "    if string[0] == u'L':\n",
        "        string_new = string[3:]\n",
        "    else:\n",
        "        string_new = string\n",
        "   \n",
        "    return string_new"
      ],
      "id": "vP_GnH9rRjup"
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "PhhuqjFPRjup"
      },
      "outputs": [],
      "source": [
        "macro_comb = []    \n",
        "for i in regresults_colst[0:paranum]:\n",
        "    i_new = u'还原' + i\n",
        "    macro_comb.append(i_new)\n",
        "    regresults[i_new] = regresults[[i]].applymap(delL)\n",
        "      \n",
        "def data_pre(row):\n",
        "    global paranum\n",
        "    row[u'还原变量组合'] = []\n",
        "    for i in range(paranum):\n",
        "        row[u'还原变量组合'].append(row[macro_comb[i]])\n",
        "    row[u'还原变量组合'] = tuple(row[u'还原变量组合'])\n",
        "    return row\n",
        "\n",
        "regresults_dict = regresults.to_dict('records')\n",
        "for key in regresults_dict:\n",
        "    data_pre(key)\n",
        "regresults = pd.DataFrame(regresults_dict)"
      ],
      "id": "PhhuqjFPRjup"
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "-o0aqXmTRjup"
      },
      "outputs": [],
      "source": [
        "##导入符合经济含义的系数符号\n",
        "def signf(x):   \n",
        "    econ_sign_x = econ_sign.loc[x,0]\n",
        "    return econ_sign_x\n",
        "\n",
        "macro_sign = []\n",
        "for i in macro_comb:\n",
        "    i_new = i + u'econ_sign'\n",
        "    macro_sign.append(i_new)\n",
        "    regresults[i_new] = regresults[[i]].applymap(signf)"
      ],
      "id": "-o0aqXmTRjup"
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "tG-9VldERjuq"
      },
      "outputs": [],
      "source": [
        "# 记录是否有变量系数符号和其经济含义不符，如有标记为0，否则标记为1\n",
        "regresults['econ_sign_tag'] = 1\n",
        "for i in regresults.index.tolist():\n",
        "    cond_lst = []\n",
        "    for j in range(paranum):\n",
        "        cond_lst.append(np.sign(float(regresults.loc[i,u'Beta'+str(j+1)])) != regresults.loc[i,macro_sign[j]])\n",
        "    if 1 in cond_lst:\n",
        "        regresults.loc[i,'econ_sign_tag'] = 0"
      ],
      "id": "tG-9VldERjuq"
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "FACOHWABRjuq"
      },
      "outputs": [],
      "source": [
        "# 记录是否有变量显著性测试不能通过，如有标记为0，否则标记为1\n",
        "regresults['significance_tag'] = 1\n",
        "for i in regresults.index.tolist():\n",
        "    cond_lst = []\n",
        "    for j in range(paranum):\n",
        "        cond_lst.append(float(regresults.loc[i,u'p'+str(j+1)]) > pcutoff)\n",
        "    if  1 in cond_lst:\n",
        "        regresults.loc[i,'significance_tag'] = 0"
      ],
      "id": "FACOHWABRjuq"
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "1RlP2rTYRjuq"
      },
      "outputs": [],
      "source": [
        "# 记录是否有变量多重共线性VIF测试不能通过，如有标记为0，否则标记为1\n",
        "regresults['vif_tag'] = 1\n",
        "for i in regresults.index.tolist():\n",
        "    cond_lst = []\n",
        "    for j in range(paranum):\n",
        "        cond_lst.append(float(regresults.loc[i,u'vif_变量'+str(j+1)]) > VIFcutoff)\n",
        "    if 1 in cond_lst:\n",
        "        regresults.loc[i,'vif_tag'] = 0"
      ],
      "id": "1RlP2rTYRjuq"
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "31eUlKcFRjuq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d54b398-fcdd-411d-cedb-e40baef08bdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "共回归 2268 组模型\n"
          ]
        }
      ],
      "source": [
        "print(u'共回归 %d 组模型' %(len(regresults)))"
      ],
      "id": "31eUlKcFRjuq"
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "3sqOz3eJRjur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c26b1406-fb33-49ec-d838-6b51a6e9e4d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "经济含义\\系数显著性\\多重共线性测试通过后有 180 组模型\n"
          ]
        }
      ],
      "source": [
        "## 去掉通不过系数经济含义测试\\显著性测试\\VIF共线性测试的模型\n",
        "regresults_sub1 = regresults[((regresults['econ_sign_tag'] == 0) & (regresults['significance_tag'] == 0) & (regresults['vif_tag'] == 0))]\n",
        "print (u'经济含义\\系数显著性\\多重共线性测试通过后有 %d 组模型' %(len(regresults_sub1))) #272组"
      ],
      "id": "3sqOz3eJRjur"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHR7ogUwRjur"
      },
      "source": [
        "### 7.4 长期均衡模型结果输出"
      ],
      "id": "tHR7ogUwRjur"
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "clemmT-2Rjur"
      },
      "outputs": [],
      "source": [
        "## 将模型按照入模宏观指标类型和R^2降序排列\n",
        "regresults = regresults.sort_values(by=[u'还原变量组合',u'R2'],ascending=False)\n",
        "regresults_sub1 = regresults_sub1.sort_values(by=[u'还原变量组合',u'R2'],ascending=False)"
      ],
      "id": "clemmT-2Rjur"
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "j1fW56AQRjur",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "1f2f692f-d590-49e8-c9f0-1003d4380914"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                R2\n",
              "count  2268.000000\n",
              "mean      0.438232\n",
              "std       0.152519\n",
              "min       0.082872\n",
              "0%        0.082872\n",
              "25%       0.304486\n",
              "50%       0.460056\n",
              "75%       0.556763\n",
              "100%      0.798644\n",
              "max       0.798644"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19cbfd31-722b-4a50-bb3f-390e5885f104\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2268.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.438232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.152519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.082872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0%</th>\n",
              "      <td>0.082872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.304486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.460056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.556763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100%</th>\n",
              "      <td>0.798644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.798644</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19cbfd31-722b-4a50-bb3f-390e5885f104')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-19cbfd31-722b-4a50-bb3f-390e5885f104 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-19cbfd31-722b-4a50-bb3f-390e5885f104');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ],
      "source": [
        "## 考察R^2的分位数\n",
        "regresults[[u'R2']].describe(include='all',percentiles=[0,0.25,0.5,0.75,1])"
      ],
      "id": "j1fW56AQRjur"
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "jaxYnLYMRjur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aff2374-a667-4e0a-fcb5-d3f1afa61851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08287248547417458\n",
            "保留0%R2后有180组模型\n"
          ]
        }
      ],
      "source": [
        "## 可以选择100%分位数\n",
        "print (np.percentile(regresults[u'R2'],R2percentile))\n",
        "regresults_sub2 = regresults_sub1[regresults_sub1[u'R2'] > np.percentile(regresults[u'R2'],R2percentile)]\n",
        "print (u'保留%d%%R2后有%d组模型' %(R2percentile,len(regresults_sub2)))"
      ],
      "id": "jaxYnLYMRjur"
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "yfoew_lERjus"
      },
      "outputs": [],
      "source": [
        "regresults_sub2.to_excel(r'output_long_term_model_8.24_滞后期数2.xlsx')"
      ],
      "id": "yfoew_lERjus"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwpQJqhpRjus"
      },
      "source": [
        "### 7.5 协整测试结果输出"
      ],
      "id": "SwpQJqhpRjus"
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "sYZLjE1jRjus"
      },
      "outputs": [],
      "source": [
        "# 对保留的模型做协整关系测试(Johansen测试)，保留通过协整测试的模型\n",
        "# 这一步之前首先人工筛选，缩小入选模型的范围\n",
        "model_nobs_lst = regresults_sub2.index.tolist() ## 注：此处可修改入选模型编号 [1002,997]\n",
        "model_nobs_lst_keep = [] #此处保存通过协整测试的模型编号\n",
        "model_nobs_lst_keep = copy.deepcopy(model_nobs_lst)\n",
        "regresults_sub3 = regresults.loc[model_nobs_lst]"
      ],
      "id": "sYZLjE1jRjus"
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "WG-UuqOWRjus"
      },
      "outputs": [],
      "source": [
        "regresults_sub3['coint_tag'] = 0\n",
        "regresults_sub3['coint_rank'] = 0"
      ],
      "id": "WG-UuqOWRjus"
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "n3uvQoFQRjus"
      },
      "outputs": [],
      "source": [
        "model_col_lst = []\n",
        "for i in range(1,paranum+1):\n",
        "    model_col_lst.append(u'变量'+str(i))"
      ],
      "id": "n3uvQoFQRjus"
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "0rYbAsJ6Rjus"
      },
      "outputs": [],
      "source": [
        "for i in model_nobs_lst:\n",
        "    model_varlst = regresults_sub3.loc[i,model_col_lst].tolist()\n",
        "    x = pd.merge(Y,X[model_varlst],how='left',left_index=True,right_index=True).dropna()\n",
        "    coint_results = coint_johansen(x, 1, coint_lag_max)\n",
        "    # print (coint_results.cvt)   # 跟踪统计的临界值\n",
        "    # print (coint_results.lr1)  # 跟踪统计\n",
        "    coint_results_cvt = []\n",
        "    for j in range(paranum+1):\n",
        "        coint_results_cvt.append(coint_results.cvt[j][coint_cutoff_map[coint_cutoff]])\n",
        "    # print (coint_results_cvt)\n",
        "    for j in range(paranum+1):\n",
        "        if j == 0 and coint_results.lr1[j] <= coint_results_cvt[j]:\n",
        "            regresults_sub3.loc[i,'coint_rank'] = 0\n",
        "            break\n",
        "        else:\n",
        "            if coint_results.lr1[j] > coint_results_cvt[j]:\n",
        "                regresults_sub3.loc[i,'coint_rank'] += 1\n",
        "                continue\n",
        "            else:\n",
        "                break\n",
        "    if regresults_sub3.loc[i,'coint_rank'] >= 3:\n",
        "        regresults_sub3.loc[i,'coint_tag'] = 1\n",
        "    if regresults_sub3.loc[i,'coint_rank'] == 4:\n",
        "        regresults_sub3.loc[i,'coint_rank'] = '> 3'\n",
        "    if regresults_sub3.loc[i,'coint_tag'] == 1:\n",
        "        model_nobs_lst_keep.append(i)"
      ],
      "id": "0rYbAsJ6Rjus"
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "KjLo5SJiRjut"
      },
      "outputs": [],
      "source": [
        "## 协整测试结果输出\n",
        "regresults_sub3 = regresults_sub3[regresults_sub3['coint_tag']==1]\n",
        "regresults_sub3.to_excel(r'output_cointegration_test_8.24_滞后期数2.xlsx')"
      ],
      "id": "KjLo5SJiRjut"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9KCrofXRjut"
      },
      "source": [
        "## 8. 对最终选定的模型，使用VECM模型，估计短期修正模型"
      ],
      "id": "F9KCrofXRjut"
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "H7-sqaNbRjut",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "outputId": "0c3491ea-6f4a-4d78-aa9e-228840a6255b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 727",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-180-5e5bac9a5435>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#从上一步保留的模型池中选定最终使用的模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_no\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m727\u001b[0m \u001b[0;31m#注：此处修改最终选定的模型编号\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mregresults_sub4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregresults_sub3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_no\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#构造各变量的一阶差分\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_varlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregresults_sub4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_col_lst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mu'fubon_npl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    836\u001b[0m                 \u001b[0;31m# We don't need to check for tuples here because those are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m                 \u001b[0;31m#  caught by the _is_nested_tuple_indexer check above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m                 \u001b[0;31m# We should never have a scalar section here, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3774\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected label or tuple of labels, got {key}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3775\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3776\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3778\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 727"
          ]
        }
      ],
      "source": [
        "#从上一步保留的模型池中选定最终使用的模型\n",
        "model_no = 727 #注：此处修改最终选定的模型编号\n",
        "regresults_sub4 = pd.DataFrame(regresults_sub3.loc[model_no,:]).T\n",
        "#构造各变量的一阶差分\n",
        "model_varlst = regresults_sub4[model_col_lst].values[0].tolist() + [u'fubon_npl']\n",
        "d_model_varlst = [u'D_' + i for i in model_varlst] + [u'fubon_npl_p',u'ecm']\n",
        "d_model_varlst_sub = [u'D_' + i for i in regresults_sub4[model_col_lst].values[0].tolist()] + [u'ecm']\n",
        "d_value = pd.DataFrame(columns=d_model_varlst)\n",
        "data_tmp = pd.merge(Y,X,how='left',left_index=True,right_index=True)\n",
        "for i in range(paranum+1):\n",
        "    d_value[d_model_varlst[i]] = data_tmp[model_varlst[i]].diff(1)\n",
        "d_value[u'fubon_npl_p'] = regresults_sub4.loc[model_no,u'Intercept']\n",
        "for i in range(paranum):\n",
        "    d_value[u'fubon_npl_p'] += regresults_sub4.loc[model_no,u'Beta'+str(i+1)]*data_tmp[model_varlst[i]]\n",
        "tmp = data_tmp[u'fubon_npl'] - d_value[u'fubon_npl_p']\n",
        "d_value[u'ecm'] = (data_tmp[u'fubon_npl'] - d_value[u'fubon_npl_p']).shift(1)"
      ],
      "id": "H7-sqaNbRjut"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UKhjeWnRjut"
      },
      "outputs": [],
      "source": [
        "#回归短期误差修正模型\n",
        "x = d_value[d_model_varlst_sub]\n",
        "x = sm.add_constant(x)\n",
        "model = sm.OLS(d_value['D_fubon_npl'],x.astype(float),missing='drop')\n",
        "results_tmp = model.fit()\n",
        "\n",
        "d_col_lst = [u'D_Intercept']\n",
        "for i in d_model_varlst_sub:\n",
        "    d_col_lst.append(u'Beta_'+i)\n",
        "for i in d_col_lst:\n",
        "    regresults_sub4.loc[model_no,i] = 0\n",
        "\n",
        "regresults_sub4[d_col_lst] = results_tmp.params.tolist()"
      ],
      "id": "4UKhjeWnRjut"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_FIqoHHRjuu"
      },
      "outputs": [],
      "source": [
        "##短期修正模型结果输出\n",
        "regresults_sub4.to_excel('output_ecm_model.xlsx')"
      ],
      "id": "U_FIqoHHRjuu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJn37FOIMMUi"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "dJn37FOIMMUi"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "富邦华一通用传导模型代码_0803.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}